[
  {
    "objectID": "index.html#a-little-about-me",
    "href": "index.html#a-little-about-me",
    "title": "Daianna Gonzalez-Padilla",
    "section": "A little about me",
    "text": "A little about me\n\nHey! Daianna here. I graduated from the undergraduate program of Genomic Sciences üß¨ at the National Autonomous University of Mexico üá≤üáΩ LCG-UNAM in Cuernavaca, Morelos, Mexico in 2024. Currently I work at the Sanger Institute in Cambridge, U.K. analyzing single-cell data from iPSC-derived microglia to unveil the genetic architecture of neurodegenerative diseases.\nDuring the last few years I‚Äôve been involved in multiple omics projects. At the Lieber Institute for Brain Development (LIBD) I analyzed transcriptomic data to explore brain develpment and function üß†, and at the Karolinska Institutet (KI) I‚Äôve studied genetic variability in genes influencing drug response and toxicity üíä. Along the way, with my undergrad courses and projects, analyzing and dealing with my own data, and attending courses, conferences, and meetings, I‚Äôve learned about statistical analyses and bioinformatic tools and I wanted to share all this knowledge with the scientific community üë•, particularly with other students like me that may not have the same opportunities or academic background but also want to analyze datasets to answer biologically-relevant questions."
  },
  {
    "objectID": "index.html#motivation-for-this-website",
    "href": "index.html#motivation-for-this-website",
    "title": "Daianna Gonzalez-Padilla",
    "section": "Motivation for this website",
    "text": "Motivation for this website\n\n\n\n\n\n\nDoing scientific research, collaborating with my classmates and peers, and assisting in bioinformatics courses I‚Äôve noticed the existence of two common problems while analyzing data:\n\nIn these interconnected times, with praiseworthy collaborative efforts such as the Bioconductor project we can easily develop, share, and use other people‚Äôs code, data, methods, and even complete packages for our own analyses. That represents an incredible opportunity for all of us to leverage, contribute, and improve popular and new-emerging computational tools for the reproducible analysis of biological data, no doubts! However, for students and novice researchers, and people coming from areas other than biostatistics, computational biology, or bioinformatics, some analyses may represent obscure-if not completely unknown‚Äìterritories. People developing these algorithms often assume they have a specialized audience and tend to trivialize underlying statistical concepts and methods when describing their computational functions and packages, not to mention the poor or even missing documentation and support some of the authors offer (with notable exceptions such as limma and variancePartition, among others).¬†\nSecond, nowadays it is incredibly simple to run a complete pipeline with a single function. That‚Äôs efficient and increases productivity but it also has diluted the needed understanding behind their use. I have found many people, including myself, deludedly thinking we master an analysis only because we have run software programs without errors and have received outputs. We may dominate the practice but that doesn‚Äôt imply nor guarantee we understand the theory.¬†\n\n\nIt seems to me we are a generation of trained students that know how to run an analysis and obtain results, but don‚Äôt understand the analyses themselves; in some occasions, not even the reasons why we execute them. But this is not limited to undergrad or master students: you would be surprised by the number of PhD students, postdocs, and researchers that relate to this!\n\n‚ùóÔ∏è‚ùóÔ∏è‚ùóÔ∏è More alarming than the aforementioned I‚Äôd say, is not to be aware of why it is important to really understand the aims and foundations of the methods we implement. It is not until we do that, that we can make accurate and informed method selections based on the features of our data, detect unexpected and error-announcing results and interpret them correctly, map potential limitations of our analyses and draw rigorous meaningful conclusions from them."
  },
  {
    "objectID": "index.html#objectives",
    "href": "index.html#objectives",
    "title": "Daianna Gonzalez-Padilla",
    "section": "Objectives",
    "text": "Objectives\n\nThe purposes of the blog posts are the following:\n\nTo diminish those ‚óºÔ∏èüì¶‚Äôs that many of these single-function methods represent, clearly showing how they operate mathematically and statistically.\nTo exemplify how to run these R/Bioconductor/Bash programs on real data, explaining their inputs and outputs, arguments and parameters.¬†\nTo present the type of analyses you can implement with your own datasets to inspire you to explore further your data and outputs.¬†\nTo show how to interpret the results.\n\nIn summary, this is a little of what I would have liked to read to feel more confident when applying a tool and explaining results derived from it."
  },
  {
    "objectID": "index.html#take-home-messages",
    "href": "index.html#take-home-messages",
    "title": "Daianna Gonzalez-Padilla",
    "section": "Take-home messages",
    "text": "Take-home messages\n\nFinally, I want to share some very important lessons I have learned so far:\n\nThere‚Äôs no better source to understand a method than going to its original publication üìë (yes, some of the last century!)¬†\nDocumentation sites won‚Äôt answer many of your theoretical questions. Tutorials, if available, are more detailed materials with usage examples and practical explanations, but again, for theory and methods check the original articles.\nStay humble. If I have become aware of something these years, it is how ignorant we are, something we only learn, paradoxically, as we acquire more knowledge by studying and investigating üìö. Taking an arrogant attitude will only stop you from nourishing yourself with more learnings and ideas, and it will close doors for you. We never stop learning!"
  },
  {
    "objectID": "index.html#feedback",
    "href": "index.html#feedback",
    "title": "Daianna Gonzalez-Padilla",
    "section": "Feedback",
    "text": "Feedback\n\nüí¨ I hope you find these materials useful. Feel free to contact me for personal doubts, inquiries, or further discussion in the comment boxes and in any of my media shown below üëáüèº. I‚Äôd also appreciate your feedback and contributions to keep improving these contents. Have fun with your analyses!\n\n\n\n\nThe website was created using¬†Quarto."
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "My Blog",
    "section": "",
    "text": "Why are p-values uniformly distributed?\n\n\n\np-value\n\nuniform distribution\n\nprobability integral transform\n\n\n\nGraphical illustration and mathematical proof of the uniform distribution of p-values\n\n\n\n\n\nFeb 7, 2025\n\n\nDaianna Gonzalez-Padilla\n\n\n\n\n\n\n\n\n\n\n\n\nWhat comes first: count normalization or gene/sample filtering?\n\n\n\nNormalization\n\nFiltering\n\nTrimmed Mean of M values\n\nLowly-expressed genes\n\nLow-quality samples\n\nRNA-seq\n\n\n\n\n\n\n\n\n\nDec 12, 2024\n\n\nDaianna Gonzalez-Padilla\n\n\n\n\n\n\n\n\n\n\n\n\nTrimmed Mean of M-values\n\n\n\nNormalization\n\nRNA composition bias\n\nTrimmed Mean of M-values\n\nLibrary size\n\nNormalization factor\n\nHighly-expressed genes\n\nDifferential Gene Expression\n\nRNA-seq\n\n\n\nDemonstration of the RNA composition bias in RNA-seq data, its impact on differential gene expression analysis, and its correction using the TMM method.\n\n\n\n\n\nDec 12, 2024\n\n\nDaianna Gonzalez-Padilla\n\n\n\n\n\n\n\n\n\n\n\n\nExploratory Data Analysis for RNA-seq data\n\n\n\nTODO\n\n\n\n\n\n\n\n\n\nDec 12, 2024\n\n\nDaianna Gonzalez-Padilla\n\n\n\n\n\n\n\n\n\n\n\n\nFisher‚Äôs exact test for enrichment analysis of gene sets\n\n\n\nFisher's exact test\n\noverrepresentation\n\nORA\n\nenrichment\n\nGene Set Enrichment Analysis\n\nGO\n\nKEGG\n\nFunctional enrichment\n\n\n\nA complete and interpretable explanation of the Fisher‚Äôs exact test in the context of gene set-based enrichment analysis. The transcriptomic applicability of this test is exemplified with a functional enrichment analysis for DEGs.\n\n\n\n\n\nAug 19, 2024\n\n\nDaianna Gonzalez-Padilla\n\n\n\n\n\n\n\n\n\n\n\n\nMAGMA: How does the Gene and the Gene-Set analysis operate?\n\n\n\nGWAS\n\nGene Analysis\n\nGene Set Analysis\n\nSNP summary statistics\n\n\n\nGlobal overview of MAGMA Gene and Gene-Set analyses and detailed practical demonstration of the SNP-wise gene analysis and the competitive gene-set analysis.\n\n\n\n\n\nJul 16, 2024\n\n\nDaianna Gonzalez-Padilla\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding False Discovery Rate and q-values\n\n\n\np-value\n\nFDR\n\nq-value\n\n\n\n\n\n\n\n\n\nJul 16, 2024\n\n\nDaianna Gonzalez-Padilla\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2024-07-13-Fisher_test/index.html",
    "href": "posts/2024-07-13-Fisher_test/index.html",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "",
    "text": "Imagine you have analyzed high-throughput omics data and have ended up with a list of candidate/interest genes (because everything is more interpretable at the gene level, isn‚Äôt?). These genes could be, for instance, differently expressed genes (DEGs), genes associated with a certain disease, genes affected by risk SNPs, markers for cell types, etc. Any list of experimentally-derived genes with biological or clinical relevance applies.\nNow, what comes after that? If you found a few genes, you can do a little of research about them and make sense of your results, but what if you got thousands of genes? That‚Äôs not an easy task anymore and becomes unscalable. Moreover, despite each individual found gene providing valuable information, we can reveal more definite insights by studying all genes at the same time.\nSo what‚Äôs to do? We need to start thinking of these genes as a unique set with its own properties, and ask questions such as what do these genes have in common? what makes them being involved or affected by the condition under study, and what does that imply for cell functionality?\nFunctional enrichment analysis based on the one-sided Fisher‚Äôs exact test aims to test whether our genes as a set are associated with certain cellular properties or functions by assessing if sets of known genes that share biological activities or attributes (functional gene sets), have a statistically significant large overlap with our genes, i.e., if such functional gene sets are, what we call over-represented (or enriched, which is the same), among our genes. Stay on this post to learn more about how this test operates and how to understand and apply it to analyze sets of genes."
  },
  {
    "objectID": "posts/2024-07-16-MAGMA/index.html",
    "href": "posts/2024-07-16-MAGMA/index.html",
    "title": "MAGMA: How does the Gene and the Gene-Set analysis operate?",
    "section": "",
    "text": "MAGMA¬†stands for¬†Multi-marker Analysis of GenoMic Annotation¬†and is a computational tool for the analysis of the joint effect of multiple genetic markers on a phenotype based on Genome-Wide Association Study (GWAS) data. MAGMA constitutes a flexible and generalizable approach to assess the¬†association¬†of¬†individual genes¬†or¬†gene-sets¬†with a¬†phenotype¬†based on the associations that the¬†SNPs¬†of the genes have with the same phenotype.\nThis is a commonly used method that you‚Äôll likely find implemented while reading about GWASes or that you‚Äôll need to run if working with genetic variant associations and gene/gene-set analysis, so let‚Äôs see how it works."
  },
  {
    "objectID": "posts/2024-07-16-MAGMA/index.html#step-1",
    "href": "posts/2024-07-16-MAGMA/index.html#step-1",
    "title": "MAGMA: How does the SNP-wise Gene and the Gene-Set analysis operate?",
    "section": "Step 1:",
    "text": "Step 1:"
  },
  {
    "objectID": "posts/2024-07-16-MAGMA/index.html#original-publication-of-magma",
    "href": "posts/2024-07-16-MAGMA/index.html#original-publication-of-magma",
    "title": "MAGMA: How does the SNP-wise Gene and the Gene-Set analysis operate?",
    "section": "",
    "text": "de Leeuw, C. A., Mooij, J. M., Heskes, T., & Posthuma, D. (2015). MAGMA: generalized gene-set analysis of GWAS data.¬†PLoS computational biology,¬†11(4), e1004219. https://doi.org/10.1371/journal.pcbi.1004219"
  },
  {
    "objectID": "posts/2024-07-16-MAGMA/index.html#gene-analysis",
    "href": "posts/2024-07-16-MAGMA/index.html#gene-analysis",
    "title": "MAGMA: How does the Gene and the Gene-Set analysis operate?",
    "section": "Gene analysis",
    "text": "Gene analysis\nGenetic markers are aggregated to the level of whole individual genes and those in a given gene are jointly tested for their association with the phenotype, defining in such way the association of the gene itself. This definitely allows to detect significant associations given by multiple small-effect markers in a gene that individually would be missed, i.e., associations that depend on multiple markers. This also reduces the number of required tests and makes the results more interpretable by summarizing at the gene level.\nTwo alternatives for gene analysis are offered by MAGMA:\n\nMultiple linear PC regression model\nIf the input data is raw genotype data, MAGMA fits a multiple linear PC regression model to the individuals‚Äô phenotypes. Here, for one gene \\(g\\) at a time, the SNP matrix that contains the information of the SNPs for that gene across all the \\(N\\) individuals studied, is projected onto its Principal Components (PCs). These PCs capture genotypic differences between individuals for the given gene and the first \\(K\\) most explanatory ones (comprising 99.9% of the variance) are used as predictors of the phenotype (\\(Y\\)) in the linear model.\n\n\n\n\n\nPhenotype is modeled as:\n\\[\nY = \\alpha_{0g}+X^*_{g}\\alpha_g+W\\beta_g+\\epsilon_g\n\\]\n\\[\n{\\begin{bmatrix}Y_1 \\\\ ... \\\\ Y_{N-1} \\\\ Y_N\\end{bmatrix}} = {\\begin{bmatrix}\\alpha_{0g} \\\\ ... \\\\ \\alpha_{0g} \\\\ \\alpha_{0g}\\end{bmatrix}} + \\stackrel{PC1 \\ \\  \\ \\  \\ \\ PC2 \\ \\  \\ \\  \\ \\ ...  \\ \\ \\ \\ \\ \\ PC_K} {\\begin{bmatrix}  x_{11} \\ \\ x_{12} \\ \\ ... \\ \\ x_{1K}  \\\\  ... \\\\ x_{(N-1)1} \\ \\ x_{(N-1)2} \\ \\ ... \\ \\ x_{(N-1)K} \\\\  x_{N1} \\ \\ x_{N2} \\ \\ ... \\ \\ x_{NK} \\end{bmatrix}} {\\begin{bmatrix}\\alpha_{g1} \\\\  \\alpha_{g2} \\\\ ... \\\\ \\alpha_{gK}\\end{bmatrix}} +  \\\\\n\\]\n\\[\n\\stackrel{Cov1 \\ \\  \\ \\  \\ \\ Cov2 \\ \\  \\ \\  \\ \\ ...  \\ \\ \\ \\ \\ \\ CovL}{\\begin{bmatrix}  w_{11} \\ \\ w_{12} \\ \\ ... \\ \\ w_{1L}  \\\\  ... \\\\ w_{(N-1)1} \\ \\ w_{(N-1)2} \\ \\ ... \\ \\ w_{(N-1)L} \\\\  w_{N1} \\ \\ w_{N2} \\ \\ ... \\ \\ w_{NL} \\end{bmatrix}}{\\begin{bmatrix}\\beta_{g1} \\\\  \\beta_{g2} \\\\ ... \\\\ \\beta_{gL}\\end{bmatrix}} +\n{\\begin{bmatrix}\\epsilon_{g1} \\\\ ... \\\\ \\epsilon_{g(N-1)} \\\\  \\epsilon_{gN}\\end{bmatrix}}\n\\]\nWith \\(X_{g}^*\\) the matrix of the first \\(K\\) PCs for gene \\(g\\) and \\(W\\) a matrix of additional covariates for the individuals that can be included in the model. \\(\\alpha_g\\)‚Äôs and \\(\\beta_g\\)‚Äôs are the coefficients of the PCs and covariates for the gene \\(g\\), respectively. \\(\\epsilon_g\\) is the vector of residuals and \\(\\alpha_{0g}\\) the intercept. The \\(\\alpha_g\\)‚Äôs represent the effect of the genotype for gene \\(g\\) on the phenotype (the genetic effect).\nThen an F-test is used to assess if genotypes for gene \\(g\\) have an effect on the phenotype under the null hypothesis that the genetic effect of \\(g\\) on the phenotype is 0 across all PCs (\\(H_0:\\alpha_g=\\overrightarrow 0\\)). This leads to a p-value for the association of gene \\(g\\) with the phenotype \\(Y\\) based on its genetic markers.\n\n‚úîÔ∏è The advantage of using PCs instead of variables for individual SNPs is that 1) the number of variables included in the linear model is reduced and 2) they allow to account for redundancy and collinearity between SNPs. Also this model offers flexibility to accommodate additional covariates to model the phenotype.\n\n\n\nSNP-wise gene analysis\nIf no raw genotype data is available, MAGMA also accepts SNP p-values from a GWAS as input. In this case SNP p-values for a gene are first transformed into Z or\\(\\chi^2\\)statistics and then combined into a gene test-statistic by the mean SNP statistic or top SNP statistic method. This gene test-statistic is then used to compute the gene p-value, either by an approximation of the sampling distribution (mean SNP statistic method) or by phenotype permutation (mean and top SNP statistic methods).\nThis SNP-wise MAGMA analysis based on SNP summary statistics requires a reference dataset with similar ancestry as the data from which SNPs p-values were computed. This is needed to account for linkage disequilibrium (LD) between SNPs. If an approximation of the sampling distribution is used to compute the gene p-value, this reference is required to obtain the SNP statistic correlation matrix \\(R\\). If phenotype permutation is chosen, these reference data are necessary to generate the gene test-statistics empirical sampling distribution.\n\nSummary: SNP p-values ‚Üí SNP statistics ‚Üí* gene test-statistic ‚Üí* gene p-value ‚Üí gene z-score (\\(z_g\\))\n\n*Gene test-statistics can be constructed from the SNP statistics applying one of the two implemented methods in MAGMA:\n\nMean SNP statistic:\n\nMean Z gene test-statistic: SNP p-values of a gene are transformed to Z-statistics and the mean (weighted or unweighted sum) of such Z-stats is used as the test-statistic of the gene: \\(T=\\sum_i^G w_iz_i\\), with \\(G\\) the total number of SNPs in the gene and \\(z_i\\) and \\(w_i\\) the Z-statistic and weight for SNP \\(i\\), respectively. These gene test-stats follow a normal distribution.\nMean \\(\\chi^2\\) gene test-statistic: the mean (weighted or unweighted sum) of the \\(-2log\\) of the SNP p-values (that are \\(\\sim\\chi^2_{(2)}\\)) is used as gene test-statistic: \\(T=-2\\sum_i^G w_i\\log(p_i)\\), with \\(p_i\\) the p-value of SNP \\(i\\). These gene test-stats are assumed to be \\(\\sim c\\chi^2_{(f)}\\), where \\(c\\) and \\(f\\) are constants of the distribution.\n\n*For both mean Z and mean \\(\\chi^2\\) gene test-statistics the p-value of the gene is obtained based on a known approximation of the sampling distribution of the gene test-stats. For such purposes, the reference dataset is needed to estimate the SNP statistic correlation matrix, from which the optional SNP weights (\\(w_i\\)) are computed to correct for dependency between SNPs. A phenotype permutation procedure can also be applied to compute empirical gene p-values (see further below).\nTop SNP statistic(s): the lowest SNP p-value among all SNPs in the gene (corresponding to the most associated SNP) or the sum of the \\(-log(p)\\) for the top most associated SNPs is used as the gene test-statistic.\n*To compute the gene p-value a phenotype permutation procedure is the only option available. Here random phenotypes are assigned to the reference data and a top gene test-statistic is computed in each permutation. The empirical gene p-value is computed as the proportion of these permuted gene test-statistics that are higher than the observed one.\n\n\n\n\n\n\n\nNote\n\n\n\nThe SNP-wise gene analysis of MAGMA can also be run with raw genotype data, in which case SNP p-values are computed internally and the raw genotype data takes place of the reference data.\n\n\nAfter running the gene analysis, either by PC regression or SNP-wise analysis, the resulting gene p-values are subsequently transformed to Z-values (\\(z_g\\)) to be introduced into the gene-set analysis. These Z-values are normally distributed and capture the association strength of the genes with the phenotype: the greater (higher positive) they are the stronger the gene association.\n\n\n\n\n\n\nCaution\n\n\n\nNote that with both PC regression and SNP-wise models we are not really looking at the sign (+/-) of the association of the genetic markers of a gene with the phenotype, just exploring if there‚Äôs an association at all:\n\nIn the PC regression model, we only assess if all genetic effects of a gene (\\(\\alpha_g\\)‚Äôs) are zero or not, but not if the global gene effect is positive or negative.\nWith SNP-wise methods, since they are based on SNP p-values that don‚Äôt inform about the sign of the association, just how strong it is, the gene test-stats derived from them are also reflecting ‚Äúsign-ignorant‚Äù associations. The gene p-value, however, is computed based on the right tail of the distribution of these gene test-stats (\\(T\\)‚Äôs) as they correspond to stronger (but not necessarily positive) associations."
  },
  {
    "objectID": "posts/2024-07-16-MAGMA/index.html#gene-set-analysis",
    "href": "posts/2024-07-16-MAGMA/index.html#gene-set-analysis",
    "title": "MAGMA: How does the Gene and the Gene-Set analysis operate?",
    "section": "Gene-set analysis",
    "text": "Gene-set analysis\nOnce having gene-level associations, we can now think of gene-set associations. Initially, we aggregate genes in groups of genes that share cellular or functional properties, such as involvements in certain biological processes, with particular molecular functions, cellular locations, cell-type specific expression or activity, or differential expression for a given condition. These define concrete processes or features we may be interested in relating with a GWAS phenotype. By doing this, we can gain insights into the potential molecules, pathways, and tissues implicated in a phenotype‚Äôs etiology.\nSince all that‚Äôs necessary from the gene analysis to run the gene-set analysis are the gene Z-values, gene-set analysis operates the same independently of the gene analysis method applied (PC regression or SNP-wise), as both result in gene p-values and respective \\(z_g\\)‚Äôs.\nTwo gene-level regression models are implemented to asses the association of gene-sets with the phenotype:\n\nSelf-contained analysis\nTests if the genes of a gene set \\(s\\) are jointly associated with the phenotype. This is assessed by an intercept-only linear regression \\(Z_s=\\beta_0\\overrightarrow1+\\epsilon_s\\), with \\(Z_s\\) the variable with the \\(z_g\\)‚Äôs of the genes in \\(s\\). With this simple model we evaluate the null \\(H_0:\\beta_0=0\\) against the alternative \\(H_A: \\beta_0&gt;0\\). This is equivalent to a one-sided single-sample t-test comparing the mean association of genes in \\(s\\) to 0. In other words, we are evaluating if the mean association strength of the genes in the set is greater than 0 (i.e., if it is a strong association, not to be confused with a positive effect of \\(s\\) on the phenotype).\n\n\n\n\n\n\n\nCompetitive analysis\nTests whether the genes in the set \\(s\\) are more strongly associated with the phenotype than the rest of genes not in the set. Here the outcome variable \\(Z\\) of the model now includes the \\(z_g\\) of all genes. We define \\(S_s\\) as a binary predictor of \\(Z\\) that equals 1 if a gene is in \\(s\\) and 0 if not: \\[Z=\\beta_{0s}\\overrightarrow1+S_s\\beta_s+\\epsilon\\]\nHere \\(\\beta_s\\) reflects the difference in the association strength of the genes in \\(s\\) versus those not in \\(s\\). The p-value of the gene set results from testing on \\(\\beta_s\\): we test \\(H_0: \\beta_s=0\\) vs \\(H_A: \\beta_s&gt;0\\), which is equivalent to a one-sided two-sample t-test evaluating if the mean association strength of genes in \\(s\\) is greater than the mean association strength of genes not in \\(s\\). But again, this doesn‚Äôt mean genes in the set \\(s\\) have a positive association with the phenotype. This analysis is performed by default.\n\n\n\n\n\n\n‚úîÔ∏è Both self-contained and competitive gene-set analyses are implemented through more general gene-level regression models that can accommodate combinations of gene sets and gene properties such as gene expression levels and gene size to test for their effects and correct for potential confounding effects. This can be useful, for example, to test if variables such as differential expression between tissues (üß† vs ü©∏) or conditions (‚öïÔ∏èvs üíä) have an effect on the phenotype.\nFurther, analyzing gene sets evidently reduces the number of output tests, but note that one test per gene still has to be performed in the the previous gene analysis.\n\n\n\n\n\n\n\nImportant\n\n\n\nDue to LD between SNPs neighboring genes are usually correlated. This obligate us to assume \\(\\epsilon \\sim MVN(\\overrightarrow0, \\sigma^2R)\\) in the gene-set analysis, where \\(R\\) is the gene-gene correlation matrix."
  },
  {
    "objectID": "posts/2024-07-16-MAGMA/index.html#step-1-annotation-of-snps-onto-genes",
    "href": "posts/2024-07-16-MAGMA/index.html#step-1-annotation-of-snps-onto-genes",
    "title": "MAGMA: How does the Gene and the Gene-Set analysis operate?",
    "section": "Step 1: Annotation of SNPs onto genes",
    "text": "Step 1: Annotation of SNPs onto genes\nThe first step is to map all SNPs from your GWAS data onto the genes of the reference genome.\n\nInput: we need SNP and gene positions based on the same human genome reference build; we provide this in the¬†.snploc¬†and in the¬†.gene.loc¬†files, respectively. MAGMA website provides gene location files ready to download.\n## .snploc file example\n## Columns: \n#  * SNP: SNP rsID\n#  * CHR: SNP chromosome\n#  * BP:  SNP position\n\n       SNP CHR         BP \nrs62513865   8  101592213 \nrs79643588   8  106973048 \nrs17396518   8  108690829 \nrs983166     8  108681675 \nrs28842593   8  103044620 \nrs7014597    8  104152280 \nrs3134156    8  100479917 \nrs6980591    8  103144592 \nrs72670434   8  108166508\n## .gene.loc file example\n## Required columns: \n#  * GeneID\n#  * Chr\n#  * Start site\n#  * Stop site\n\nENSG00000243485 1 29554 31109 + MIR1302-2HG \nENSG00000186092 1 65419 71585 + OR4F5 \nENSG00000238009 1 89295 133723 - AL627309.1 \nENSG00000239906 1 139790 140339 - AL627309.2 \nENSG00000236601 5 180881343 180888537 - AL732372.1 \nENSG00000235146 1 523009 530148 + AC114498.1 \nENSG00000229905 1 696291 697369 + AL669831.2 \nENSG00000237491 1 714150 745440 + AL669831.5\n\n\n\n\n\n\nNote\n\n\n\nSNPs in sexual chromosomes are usually excluded from the analysis as their inclusion brings additional analytical, statistical, and bioinformatic challenges for their analysis (Sun et al. 2023). MAGMA only supports X chromosome analysis.\n\n\nCommands: the following are the flags and inputs used to map the SNPs onto genes.\n## Run SNP annotation\n#  --annotate: flag to run annotation \n#  --snp-loc: indicate file with SNP positions\n#  --gene-loc: indicate file with gene positions\n#  --out: prefix for output files\n\nmagma --annotate \\ \n      --snp-loc [.snploc file]\\ \n      --gene-loc [gene.loc file]\\ \n      --out [output_prefix]\nOutput: this step returns the .genes.annot file as output, containing all SNPs that were assigned to each gene.\n## .genes.annot file example\n## Columns: \n#  * GeneID\n#  * Chr:Start:Stop\n#  * Corresponding gene SNP rsIDs\n\nwindow_up = 0 \nwindow_down = 0 \nENSG00000237491 1:714150:745440 rs186002080 rs12184267 rs142557973 rs149887893 \nENSG00000177757 1:752751:755217 rs3115859 rs3131968 rs3131967 rs3115860 \nENSG00000225880 1:761586:762902 rs2286139 rs377377186 rs374493323 \nENSG00000230368 1:803451:812283 rs11240779 rs28410559 rs72631880 rs58686784"
  },
  {
    "objectID": "posts/2024-07-16-MAGMA/index.html#step-2-snp-wise-gene-analysis",
    "href": "posts/2024-07-16-MAGMA/index.html#step-2-snp-wise-gene-analysis",
    "title": "MAGMA: How does the Gene and the Gene-Set analysis operate?",
    "section": "Step 2: SNP-wise gene analysis",
    "text": "Step 2: SNP-wise gene analysis\n\nInput: we need to provide the SNP p-values in a .pval file and the gene-wise SNPs in the .genes.annot file obtained in the previous step. A reference dataset must be provided as well. Check available options of reference data files in the MAGMA website.\nThe total sample size (N) of the GWAS from which the SNP p-values were derived must be indicated as well using the N modifier of --pval. Alternatively, if different sample sizes were used per SNP, these can be contained in a separate column of the .pval file whose name is specified in the ncol modifier of --pval.\n## .pval file example\n## Columns: \n#  * SNP: SNP ID\n#  * P: SNP p-value\n#  * N: optional SNP sample size \n\n       SNP      P      N \nrs62513865 0.4847 130644 \nrs79643588 0.5605 130644 \nrs17396518 0.8145 130644 \nrs983166   0.5704 130644 \nrs28842593 0.7488 130644 \nrs7014597  0.5034 130644 \nrs3134156  0.2225 130644\nThe next is a head of the 1000 Genomes European panel data used as the reference dataset.\n## g1000_eur reference data example\n## Columns: \n#  * Chr\n#  * SNP rsID\n#  * Genetic distance \n#  * Position\n#  * Allele1\n#  * Allele2\n\n1 rs537182016 0 10539 A C \n1 rs575272151 0 11008 G C \n1 rs544419019 0 11012 G C \n1 rs540538026 0 13110 A G \n1 rs62635286  0 13116 G T \n1 rs200579949 0 13118 G A \nCommands: the following are the flags and files required to run the SNP-wise mean Z-stats method.\n## Run gene analysis based on SNP p-values\n#  --bfile: indicate reference dataset\n#  --pval: indicate file with SNP p-values\n#                       ncol: colname for SNP samples sizes in .pval file\n#    (or alternatively) N: integer for total sample size of study\n#  --gene-annot: indicate file with gene SNPs\n#  --out: prefix for output files\n\nmagma \n--bfile [reference file]\\ \n--pval [.pval file] ncol=[colname for N]\\ \n--gene-annot [.genes.annot file]\\ \n--out [output_prefix]\nOutput: the output of the gene analysis are the gene p-values and the gene \\(z_g\\)‚Äôs. Also returned is the gene correlation matrix \\(R\\) used to account for LD in the gene-set analysis (step 3).\nTwo files are returned as output: the .genes.out file that contains the gene analysis results in a human-readable format and the .genes.raw file that is an intermediary file input for gene-set analysis that also includes the gene correlations.\n## .genes.out output file example\n#  * NSNPS: number of SNPs assigned to each gene \n#  * NPARAM: number of relevant parameters (such as PCs) used in the model for each gene \n#  * N: sample size for analyzing the gene \n#  * ZSTAT: gene z-value \n#  * P: gene p-value \n\n           GENE CHR  START   STOP NSNPS NPARAM      N    ZSTAT       P \nENSG00000237491   1 714150 745440    16      5 104688 0.59488  0.27596 \nENSG00000177757   1 752751 755217    11      2 114792 0.22362  0.41153 \nENSG00000225880   1 761586 762902     2      1 110271 0.18366  0.42714 \nENSG00000230368   1 803451 812283    10      3 120884 -1.2421   0.8929 \nENSG00000272438   1 840214 851356    32      4 116196  1.1083  0.13386 \nENSG00000223764   1 852245 856396    17      3 116843  1.2828 0.099786 \n## .genes.raw output file example\n\nVERSION = 110 \nCOVAR = NSAMP MAC \nENSG00000237491 1 714150 745440 16 5 104688 63.625 0.594875 \nENSG00000177757 1 752751 755217 11 2 114792 103 0.223624 0.772254 \nENSG00000225880 1 761586 762902 2 1 110271 87 0.183658 0.825082 0.943709 \nENSG00000230368 1 803451 812283 10 3 120884 106.7 -1.24209 0.220645 0.404423 0.341011 ENSG00000272438 1 840214 851356 32 4 116196 212.625 1.10832 0.0435105 0.0410553 0.0368872"
  },
  {
    "objectID": "posts/2024-07-16-MAGMA/index.html#step-3-competitive-gene-set-analysis",
    "href": "posts/2024-07-16-MAGMA/index.html#step-3-competitive-gene-set-analysis",
    "title": "MAGMA: How does the Gene and the Gene-Set analysis operate?",
    "section": "Step 3: Competitive gene-set analysis",
    "text": "Step 3: Competitive gene-set analysis\n\nInput: this analysis takes the \\(z_g\\) for each gene obtained in the previous step (in the .genes.raw file) and the gene sets of interest.\n## gene_sets.txt file example\n## Columns:\n#  * Gene: gene ID\n#  * Set: set to which the gene belongs\n\n           Gene   Set \nENSG00000164647  SetA \nENSG00000105889  SetA \nENSG00000085117  SetA \nENSG00000071794  SetA \n      ...         ...\nENSG00000135535  SetF \nENSG00000183230  SetF \nENSG00000124493  SetF\nCommands:\n## Competitive GSA \n#  --gene-results: indicate file with gene z-values\n#  --set-annot: indicate file with gene sets\n#               gene-col: colname for genes   \n#               set-col:  colname for sets\n#  --out: name of output folder\n\nmagma \n--gene-results [.genes.raw file]\\ \n--set-annot [gene_sets.txt file] \n            gene-col=Gene \n            set-col=Set\\ \n--out [output folder]\nOutput: the file .gsa.out contains the primary results of the competitive gene-set analysis.\n## .gsa.out output file example\n#  * VARIABLE: gene set name \n#  * TYPE: type of variable (set) \n#  * NGENES: size of overlap between our genes in the set and genes with assigned SNPs\n#            (i.e. number of genes in the set with SNPs) \n#  * BETA: regression coeff (Bs) for Ss \n#  * BETSA_STD: semi-standarized regression coeff. \n#               This is the predicted change in Z by a change of one sd in the \n#               predictor gene set (i.e., Bs/sd(Ss)) \n#  * SE: standard error of Bs\n#  * P: p-value for the set \n\nTOTAL_GENES = 28129  ## Total number of genes included in the analysis \nTEST_DIRECTION = one-sided, positive (set), two-sided (covar)  ## one-sided (+) test for GSA \nCONDITIONED_INTERNAL = gene size, gene density, sample size, inverse mac, log(gene size), log(gene density), log(sample size), log(inverse mac)  ## Variables the analysis was conditioned on \n\nVARIABLE TYPE NGENES      BETA  BETA_STD        SE      P \n    SetA  SET   2557  0.045582  0.013104  0.020419 0.0128 \n    SetB  SET    395  0.071821  0.008451  0.051418 0.081242 \n    SetC  SET    850 -0.039813 -0.0068155 0.034848 0.87337 \n    SetD  SET    163  0.033361  0.0025322 0.079059 0.33652 \n    SetE  SET   1709  0.083787  0.020016  0.02423  0.00027251 \n    SetF  SET    232  0.099547  0.0090033 0.067531 0.0702\n\nThe .gsa.sets.genes.out file provides per-gene information for each gene set. The \\(z_g\\)‚Äôs used for the analysis are shown in this file and in .gsa.genes.out that has information for all genes in the analysis.\n\n\n\n\n\n\nImportant\n\n\n\nHere NGENES doesn‚Äôt always match the number of genes provided for a set. That‚Äôs because these genes must 1) exist in the .gene.loc file in order to be assigned SNPs, and 2) have SNPs present in the GWAS study and in the reference data as only the ones included in this latter file are used. This is because only genes with SNP p-values can be assigned a \\(z_g\\) and consequently be introduced into the gene-set analysis (see schematic representation below).\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThere must be an overlap &gt;1 between genes in the set and genes with assigned SNPs (i.e.¬†NGENES &gt;1) to yield results. Otherwise MAGMA can‚Äôt perform the GSA and returns NA.\n\n\nA visual representation of these three steps:"
  },
  {
    "objectID": "posts/2024-07-13-Fisher_test/index.html#creating-and-understanding-contingency-tables",
    "href": "posts/2024-07-13-Fisher_test/index.html#creating-and-understanding-contingency-tables",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "1. Creating and understanding contingency tables",
    "text": "1. Creating and understanding contingency tables\nThe following are the required gene sets and their specifications. Please note that when referring a set of genes, we are specifically referring to the set of gene IDs; that all we need to run this test!\n\nGene universe/background: these are all the genes that were experimentally measured and interrogated to derive into the list of interest genes (our gene set). In our hypothetical scenario this is given by all genes that were assessed for DGE: all genes that can be classified as either DEG or non-DEG.\n‚Üí Let‚Äôs denote as ‚ÄúDE‚Äù the variable defining if a gene is differentially expressed (DEG) or not (non-DEG).\n\n\n\n\n\n\nHow to find my gene universe?\n\n\n\nNote that since we are testing enrichment of functional gene sets among our DEGs, and not the other way around, our ‚Äúgene universe‚Äù must correspond to the total number of genes for which we assessed DGE. Within those genes, categorized by DE, we search for genes contained in a functional set.\n\n\nOur gene set: a list of interest genes derived from our experimental measurements and analyses, and to which we want to assign biological meanings. In our hypothetical case this is the list of DEGs from all available genes that were assessed for DGE (i.e.¬†the gene universe).\n\n\n\nFunctional gene set: a set of genes with shared biological attributes (e.g.¬†participation in a given pathway, implication in the same biological process, sharing a molecular activity, or if their gene products are located in a certain cell compartment). Conveniently, functional gene sets are accessible via databases such as Gene Ontology (GO) (Ashburner et al. 2000) and the Kyoto encyclopedia of genes and genomes (KEGG) (Kanehisa 2000).\n‚Üí Let‚Äôs denote as ‚ÄúBP‚Äù the variable determining if a gene is involved in a particular biological process (BP+) or not (BP-).\n\nFisher‚Äôs exact test aims to detect functional gene sets whose genes are unusually represented (enriched/over-represented or under-represented) in our set of interest genes. That is, if there‚Äôs a large (or small) overlap between the genes of the functional set (BP+ genes in this case) and the genes we classified as relevant from our data (DEGs in this case).\nFollowing our hypothetical example, let‚Äôs suppose we have analyzed DGE for a total of 32 genes and of these 15 were DEGs. Suppose we have a functional gene set containing 12 genes involved in a biological process (BP+) and of these 9 were DEGs. Having identified such gene sets, we proceed to create a 2x2 contingency table showing the number of genes that belong to each category for each variable.\n\n\n\n\n\nThe numbers of DEGs, non-DEGs, BP+ genes, and BP- genes are called the marginal values, as they lie on the periphery of this 2x2 table. The middle cells (\\(a\\)‚Äôs) are the joint values, as they contain the overlap between the categories of the two variables.\n\n\n\n\n\n\nNote\n\n\n\nNote that by changing only one joint value, say \\(a_{11}\\), all the remaining joint values will be already determined since the marginals are fixed. In that way we can describe whole contingency tables with just their \\(a_{11}\\) corner values.\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen we say ‚Äúassociation‚Äù between DE and BP please note that it could be either positive or negative, with the former implying a larger overlap between DEGs and BP+ genes, thus corresponding to enrichment, and the latter implying a smaller overlap and thus meaning depletion. We‚Äôll also delve into the statistical implications of each type of association later."
  },
  {
    "objectID": "posts/2024-07-13-Fisher_test/index.html#assessing-gene-set-enrichment",
    "href": "posts/2024-07-13-Fisher_test/index.html#assessing-gene-set-enrichment",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "2. Assessing gene set enrichment",
    "text": "2. Assessing gene set enrichment\nThe Fisher‚Äôs exact test is used to determine the probability of observing a certain joint value (\\(a_{11}\\)) within the actual contingency table under the null hypothesis (\\(H_0\\)) that there‚Äôs no assoaciation between the categorical variables, i.e., that they are independent.\nStrictly, we estimate the probability that \\(a_{11}\\) in our table or a more extreme joint value (and their respective contingency tables for the same fixed marginal totals) would occur under the null hypothesis. These probabilities are referred to as p-values. **"
  },
  {
    "objectID": "posts/2024-07-13-Fisher_test/index.html#assessing-gene-set-depletion",
    "href": "posts/2024-07-13-Fisher_test/index.html#assessing-gene-set-depletion",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "3. Assessing gene set depletion?",
    "text": "3. Assessing gene set depletion?"
  },
  {
    "objectID": "posts/2024-08-11-Fisher_test/index.html",
    "href": "posts/2024-08-11-Fisher_test/index.html",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "",
    "text": "Imagine you have analyzed high-throughput omics data and have ended up with a list of candidate/interest genes. These genes could be, for instance, differentially expressed genes (DEGs), genes associated with a certain disease, genes affected by risk SNPs, markers for cell types, etc. Any list of experimentally-derived genes with biological or clinical relevance applies.\nNow, what comes after that? If you found a few genes, you can do a little of research about them and make sense of your results, but what if you got thousands of genes? That‚Äôs not an easy task anymore and becomes unscalable. Moreover, despite each individual found gene providing valuable information, we can reveal more definite insights by studying all genes at the same time.\nSo what‚Äôs to do? We need to start thinking of these genes as a unique set with its own properties, and ask questions such as what do these genes have in common? what makes them being involved or affected by the condition under study, and what does that imply for cell functionality?\nFunctional enrichment analysis based on the one-sided Fisher‚Äôs exact test (aka over-representation analysis (ORA) in the field) aims to test whether our genes as a set are associated with certain cellular properties or functions by assessing if sets of known genes that share biological activities or attributes (functional gene sets), have a statistically significant large overlap with our genes, i.e., if such functional gene sets are, what we call over-represented (or enriched, which is the same), among our genes. Stay on this post to learn more about how this test operates and how to understand and apply it to analyze sets of genes."
  },
  {
    "objectID": "posts/2024-08-11-Fisher_test/index.html#creating-and-understanding-contingency-tables",
    "href": "posts/2024-08-11-Fisher_test/index.html#creating-and-understanding-contingency-tables",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "1. Creating and understanding contingency tables",
    "text": "1. Creating and understanding contingency tables\nThe following are the required gene sets and their specifications. Please note that when referring to a set of genes, we are specifically referring to the set of gene IDs; that all we need to run this test!\n\nGene universe/background: these are all the genes that were experimentally measured and interrogated to generate the list of interest genes (our gene set). In our hypothetical scenario this is given by all genes that were assessed for DGE.\n‚Üí Let‚Äôs denote as ‚ÄúDE‚Äù the variable defining if a gene is differentially expressed (DEG) or not (non-DEG).\n\n\n\n\n\n\nTipHow to find my gene universe?\n\n\n\nSince we are testing enrichment of functional gene sets among our DEGs, and not the other way around, our ‚Äúgene universe‚Äù must correspond to the total number of genes for which we assessed DGE. Within those genes, categorized by DE, we search for genes contained in a functional set.\n\n\nExperimentally-derived gene set (our gene set): a list of interest genes derived from our experimental measurements and analyses, and to which we want to assign biological meanings. In our example case this is the list of DEGs from the gene universe.\nFunctional gene set: a set of genes with shared biological attributes (e.g.¬†participation in a pathway, implication in the same biological process, sharing a molecular activity, or if their gene products are located in a certain cell compartment). Conveniently, functional gene sets are accessible via knowledgebases such as Gene Ontology (GO) (Ashburner et al. 2000) and the Kyoto encyclopedia of genes and genomes (KEGG) (Kanehisa 2000).\n‚Üí Let‚Äôs denote as ‚ÄúBP‚Äù the variable determining if a gene is involved in the biological process (BP+) or not (BP-).\n\n\n\n\n\n\n\nImportant\n\n\n\nThere may be cases where you have some genes in your functional set that are not present in the gene universe. Since they were not tested for DGE we can‚Äôt categorize them as DEGs or non-DEGs. Despite this, given that we often assume most genes are non-DEGs, you can either consider them as such or exclude them from the analysis to avoid introducing ambiguous information.\n\n\nFisher‚Äôs exact test aims to detect functional gene sets whose genes are unusually represented (enriched/over-represented or under-represented) in our set of interest genes. That is, if there‚Äôs a large (or small) overlap between the genes of the functional set (BP+ genes in this case) and the genes we classified as relevant from our data (DEGs in this case).\nFollowing our hypothetical example, let‚Äôs suppose we have analyzed DGE for a total of 32 genes and of these 15 were DEGs. Suppose we have a functional gene set containing 12 genes involved in a biological process (BP+) and of these 9 were DEGs. Having identified such gene sets, we proceed to create a 2x2 contingency table showing the number of genes that belong to each category for each variable.\n\n\n\n\n\nThe numbers of DEGs, non-DEGs, BP+ genes, and BP- genes are called the marginal values, as they lie on the periphery of this 2x2 table. The middle cells (\\(a\\)‚Äôs) are the joint values, as they represent the overlap between the categories of the two variables.\n\n\n\n\n\n\nNote\n\n\n\nNote that by modifying only one joint value, say \\(a_{11}\\), all the remaining joint values will be already determined since the marginals are fixed. In that way we can describe whole contingency tables with only their \\(a_{11}\\) corner values.\n\n\n\n## Define example gene universe: 32 total genes analyzed \ngene_universe &lt;- c(\"Srsf5\", \"Gm15387\", \"Mprip\", \"Pim1\", \"Bnip3l\", \"Efr3a\", \"Marco\", \"Tuba1a\", \"Gsk3a\",\n                   \"Dap3\", \"Tmod3\", \"Dnajb1\", \"Tulp4\", \"Lsm14b\", \"Khdrbs2\", \"Mfsd9\", \"Ufd1\", \"Ypel5\",\n                   \"Rbm3\", \"Dnajc28\", \"Msrb2\", \"Memo1\", \"Cebpg\", \"Flywch1\", \"Ip6k1\", \"Nudt4\", \"Csnk1e\",\n                   \"Qsox2\", \"Gm43517\", \"Rhbdf2\", \"Fbxw11\", \"Hmgxb4\") \nlength(gene_universe)\n\n[1] 32\n\n## Define 15 DEGs from universe\nset.seed(08122024)\nDEGs &lt;- sample(gene_universe, 15, replace = FALSE)\nDEGs\n\n [1] \"Srsf5\"   \"Flywch1\" \"Ip6k1\"   \"Cebpg\"   \"Nudt4\"   \"Ypel5\"   \"Marco\"  \n [8] \"Csnk1e\"  \"Qsox2\"   \"Gsk3a\"   \"Dap3\"    \"Tuba1a\"  \"Efr3a\"   \"Hmgxb4\" \n[15] \"Gm15387\"\n\nlength(unique(DEGs))\n\n[1] 15\n\n## Remaining 17 non-DEGs\nnon_DEGs &lt;- gene_universe[!gene_universe %in% DEGs]\n\n## Functional set of 12 BP+ genes (with 9 being DEGs)\nfunct_gene_set &lt;- c(sample(DEGs, 9, replace = FALSE), sample(non_DEGs, 3, replace = FALSE))\nlength(unique(funct_gene_set))\n\n[1] 12\n\n## BP- genes: genes in universe not in functional set\ngenes_not_func_set &lt;- gene_universe[!gene_universe %in% funct_gene_set]\n\n## Intersections:\n# 1. DEGs and BP+ genes\nDEGs_in_set &lt;- intersect(DEGs, funct_gene_set)\n\n# 2. non-DEGs and BP+ genes\nnon_DEGs_in_set &lt;- intersect(non_DEGs, funct_gene_set)\n\n# 3. DEGs and BP- genes\nDEGs_not_in_set &lt;- intersect(DEGs, genes_not_func_set)\n\n# 4. non-DEGs and BP- genes\nnon_DEGs_not_in_set &lt;- intersect(non_DEGs, genes_not_func_set)\n  \n## Create contingency table\nm &lt;- matrix(c(length(DEGs_in_set), length(DEGs_not_in_set), \n            length(non_DEGs_in_set), length(non_DEGs_not_in_set)), \n            byrow = TRUE, nrow = 2)\nm\n\n     [,1] [,2]\n[1,]    9    6\n[2,]    3   14\n\n\n\n\n\n\n\n\nImportant\n\n\n\nWhen we test for ‚Äúassociation‚Äù between DE and BP note that it could be either positive or negative, with the former implying a larger overlap between DEGs and BP+ genes, and thus corresponding to enrichment, and the latter implying a smaller overlap and thus meaning depletion. We‚Äôll also delve into the statistical implications of each type of association in the next sections."
  },
  {
    "objectID": "posts/2024-08-11-Fisher_test/index.html#assessing-gene-set-enrichment",
    "href": "posts/2024-08-11-Fisher_test/index.html#assessing-gene-set-enrichment",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "2. Assessing gene set enrichment",
    "text": "2. Assessing gene set enrichment\nThe Fisher‚Äôs exact test is used to determine the probability of observing a certain joint value (\\(a_{11}\\)) within the actual contingency table under the null hypothesis (\\(H_0\\)) that there‚Äôs no assoaciation between the categorical variables, i.e., that they are independent.\nStrictly, we estimate the probability that \\(a_{11}\\) in our table or a more extreme joint value (and their respective contingency tables for the same fixed marginal totals) would occur under the null hypothesis. These probabilities are referred to as p-values. **"
  },
  {
    "objectID": "posts/2024-08-11-Fisher_test/index.html#assessing-gene-set-depletion",
    "href": "posts/2024-08-11-Fisher_test/index.html#assessing-gene-set-depletion",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "Assessing gene-set depletion?",
    "text": "Assessing gene-set depletion?\nWhat if we are not only interested in assessing the over-representation of gene sets in our experimentally-derived gene list, but also in their under-representation? There may be fewer BP+ genes in the group of DEGs than expected by chance. In such case we‚Äôd be assessing for a negative association between the variables and we need to sum the probabilities of our table and those that are less extreme.\n\n## Color in red x&lt;=9\ncolors &lt;- c(rep('red', 10), rep('beige', 3))\ndf$colors &lt;- colors\n\nggplot(df, aes(x=x, y=p, label=p, fill=colors)) +\n                theme_classic() +\n                geom_bar(stat=\"identity\", fill= colors, colour=\"black\") +\n                geom_text(label=signif(probabilities, 2),\n                                    y=probabilities, size=3, hjust=0.5, vjust=-1) +\n                labs(x = \"Number of BP+ DEGs\", y = \"Probability\")\n\n\n\n\n\n\n\n\n\n## p-value:\nsum(probabilities[1:10])\n\n[1] 0.9980864\n\n\nIn this case we use fisher.test(alternative = ‚Äùless‚Äù) and obtain the same p-value.\n\n## Same with fisher.test(alternative = \"less\")\nfisher.test(m, alternative = \"less\")    \n\n\n    Fisher's Exact Test for Count Data\n\ndata:  m\np-value = 0.9981\nalternative hypothesis: true odds ratio is less than 1\n95 percent confidence interval:\n  0.00000 37.74069\nsample estimates:\nodds ratio \n  6.529133"
  },
  {
    "objectID": "posts/2024-08-11-Fisher_test/index.html#testing-for-gene-set-enrichment",
    "href": "posts/2024-08-11-Fisher_test/index.html#testing-for-gene-set-enrichment",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "2. Testing for gene-set enrichment",
    "text": "2. Testing for gene-set enrichment\nThe Fisher‚Äôs exact test is used to determine the probability of observing the joint value \\(a_{11}\\) in our table or a more extreme value (for contingency tables with the same fixed marginal totals) under the null hypothesis (\\(H_0\\)) that there‚Äôs no association between the categorical variables, i.e., that they are independent. These probabilities are referred to as p-values. Smaller probabilities offer strong evidence against the null hypothesis, which is translated into statistical evidence to accept the alternative hypothesis (\\(H_A\\)) of association between the two variables.\nThis is how it operates:\n\nGiven the fixed marginal totals, we first we compute all possible contingency tables by enumerating all possible joint values \\(a_{11}\\): in this case from 0 to 12, which are the minimum and maximum number of genes that can be both DEGs and BP+, respectively.\n\n\n\n\n\n\n\n‚ùóÔ∏è The top left cell (\\(a_{11}\\)) of each table always corresponds to the joint value positive for both variables under examination (BP+ DEGs).\n\n\n\nThen we estimate the probability of having such joint values in each contingency table under the null hypothesis. To do that we need to calculate the number of ways of obtaining the joint values by randomness in the gene selection process. Only 3 values need to be estimated for that:\n\nThe ways of selecting \\(a_{11} + a_{12}\\) = 15 genes (corresponding to the number of DEGs) without replacement from the total genes in the gene universe: \\({a_{11} + a_{12} + a_{21} + a_{22}} \\choose a_{11} + a_{12}\\)\n\n\n\n\n\nThe ways of selecting \\(a_{11}\\) = 9 genes (number of BP+ DEGs) without replacement out of the \\(a_{11} + a_{21}\\) = 12 genes in the functional set (BP+ genes): \\({{a_{11} + a_{21}} \\choose a_{11}}\\)\n\n\n\n\n\nThe ways of selecting \\(a_{12}\\) = 6 genes (number of BP- DEGs) without replacement out of the \\(a_{12}+a_{22}\\) = 20 genes not in the functional set (BP- genes): \\({a_{12}+a_{22}}\\choose{a_{12}}\\)\n\n\n\n\n\n\n\nWith these 3 values we define the probability of each table arrangement by:\n\\[\np=\\frac{{{a_{11}+a_{21}}\\choose a_{11}} \\times {{a_{12}+a_{22}}\\choose{a_{12}}} }{{a_{11}+a_{12}+a_{21}+a_{22}}\\choose{a_{11}+a_{12}}}\n\\]\nThis is precisely the probability function for the hypergeometric distribution, used for sampling without replacement and which we use to test the null hypothesis.\n\\[\np(x)=\\frac{{m \\choose x} {n \\choose {k-x}}}{{m+n}\\choose k}\\]\n\n\\(k\\) is the sample size (number of DEGs) = \\(a_{11} + a_{12}\\) = 15\n\\(m\\) is the number of successes in the population (number of BP+ genes) = \\(a_{11} + a_{21}\\) = 12\n\\(n\\) is the number of failures in the population (number of BP- genes) = \\(a_{12} + a_{22}\\) = 20\n\\(x\\) is the number of successes in the sample (number of BP+ among DEGs) = \\(a_{11}\\) = 9\n\\(k-x\\) is the number of failures in the sample (number of BP- among DEGs) = \\(a_{12}\\) = 6\n\\(m+n\\) is the population size (size of gene universe) = \\(a_{11} + a_{12} + a_{21} + a_{22}\\) = 32\n\n\n\n\n\n\n\nTipHow to interpret the above formula?\n\n\n\nBasically, we are quantifying the number of ways of obtaining a sample of size \\(k\\) composed of \\(x\\) successes from a total of \\(m\\) successes in the population AND the remaining \\(k-x\\) elements as failures from a total of \\(n\\) failures in the population; of all possible ways of randomly selecting \\(k\\) elements from the population.\n\n\nTransferred to our scenario, think of it as having 15 chances to select genes without replacement from the universe that contains both BP+ and BP- genes. Repeat the experiment multiple times and count the times that 9 of the 15 genes you selected were BP+ (out of 12 BP+ genes in total) and the remaining 6 genes BP- (out of 20 BP- genes in total), over the number of experiments; that approximates your probability. This probability describes how likely it is to observe your table numbers (9 BP+ and 6 BP- genes in the sample of 15 DEGs) just by chance.\n\n\n\n\n\nFor our actual contingency table \\(p(x=9)=\\frac{{12 \\choose 9} \\times {20\\choose6}}{32\\choose15}\\):\n\n## Calculate manually\nchoose(12,9)*choose(20,6) / choose(32,15)\n\n[1] 0.01507311\n\n\nLet‚Äôs use dhyper() to obtain the density function for the hypergeometric distribution with the above parameters and confirm we get the same probability for \\(x\\) = 9.\n\nlibrary(ggplot2)\n\n## Hypergeometric distribution parameters:\n##  -x = 0:12 (a11 for all possible tables)\n##  -m = 12 \n##  -n = 20\n##  -k = 15\n\nprobabilities &lt;- dhyper(x=c(0:12), m=12, n=20, k=15, log = FALSE)\nxs &lt;- c(0:12)\ndf &lt;- data.frame(x=xs, p=probabilities)\ndf \n\n    x            p\n1   0 2.740565e-05\n2   1 8.221696e-04\n3   2 9.043865e-03\n4   3 4.898760e-02\n5   4 1.469628e-01\n6   5 2.586545e-01\n7   6 2.743306e-01\n8   7 1.763554e-01\n9   8 6.782899e-02\n10  9 1.507311e-02\n11 10 1.808773e-03\n12 11 1.027712e-04\n13 12 2.015121e-06\n\n# Bar plot\nggplot(df, aes(x=x, y=p, label=p)) +\n     theme_classic() + \n     geom_bar(stat=\"identity\", fill= \"beige\", colour=\"black\") +\n     geom_text(label=signif(probabilities, 2), \n                             y=probabilities, size=3, hjust=0.5, vjust=-1) +\n     labs(x = \"Number of BP+ DEGs\", y = \"Probability\")\n\n\n\n\n\n\n\n\n\nOne-sided test\nAs mentioned before, we are not only interested in the probability of the observed contingency table but also in those for more extreme contingency tables, i.e., tables with greater \\(a_{11}\\)‚Äôs.\n\n\n\n\n\nWe add the probability of the actual table + the probabilities for such more extreme tables in order to get the probability of observing 9 or more DEGs that are BP+ under the null hypothesis:\n\n## p(x&gt;=9)\nsum(probabilities[10:13])\n\n[1] 0.01698667\n\n\nSince p &lt;0.05 we reject the null hypothesis and accept that there‚Äôs an enrichment of BP+ genes amongst our DEGs, and hence the biological process has a significant positive association with differential gene expression.\nThis is called a one-sided Fisher‚Äôs exact test as we are evaluating probabilities of extreme values on only one side of the density curve (values \\(a_{11}\\)‚â•9 for enrichment; see plot below).\n\n## Color in red those x&gt;=9\ncolors &lt;- c(rep('beige', 9), rep('red', 4))\ndf$colors &lt;- colors\nggplot(df, aes(x=x, y=p, label=p, fill=colors)) +\n                theme_classic() +\n                geom_bar(stat=\"identity\", fill= colors, colour=\"black\") +\n                geom_text(label=signif(probabilities, 2),\n                                    y=probabilities, size=3, hjust=0.5, vjust=-1) +\n                labs(x = \"Number of BP+ DEGs\", y = \"Probability\")\n\n\n\n\n\n\n\n\nWe obtain the same result with fisher.test(alternative = ‚Äùgreater‚Äù):\n\nfisher.test(m, alternative = \"greater\") \n\n\n    Fisher's Exact Test for Count Data\n\ndata:  m\np-value = 0.01699\nalternative hypothesis: true odds ratio is greater than 1\n95 percent confidence interval:\n 1.402791      Inf\nsample estimates:\nodds ratio \n  6.529133 \n\n\n\n\n\n\n\n\nNote\n\n\n\nNote that the results of this test are the same for the transposed matrix, so if we put one or the other variable in columns or rows doesn‚Äôt affect as long as the first element of the table is the number of successes in the sample (BP+ DEGs).¬†\n\n## Matrix\nm\n\n     [,1] [,2]\n[1,]    9    6\n[2,]    3   14\n\n## Transposed matrix\nt(m)     \n\n     [,1] [,2]\n[1,]    9    3\n[2,]    6   14\n\n## Fisher test on t(m)\nfisher.test(t(m), alternative = \"greater\")  \n\n\n    Fisher's Exact Test for Count Data\n\ndata:  t(m)\np-value = 0.01699\nalternative hypothesis: true odds ratio is greater than 1\n95 percent confidence interval:\n 1.402791      Inf\nsample estimates:\nodds ratio \n  6.529133"
  },
  {
    "objectID": "posts/2024-08-11-Fisher_test/index.html#two-sided-test",
    "href": "posts/2024-08-11-Fisher_test/index.html#two-sided-test",
    "title": "Fisher‚Äôs exact test for enrichment analysis of gene sets",
    "section": "Two-sided test",
    "text": "Two-sided test\nThe two-sided Fisher‚Äôs exact test is based on both tails of the hypergeometric distribution and is thus used when we want to evaluate if there‚Äôs any association between the variables irrespective of the sign (assessing for both enrichment and depletion).\nOne approach to account for extreme values on both sides is to double the sum of the extreme tables‚Äô probabilities on one side (i.e.¬†the one-sided p-value):\n\n## p-value\n2*sum(probabilities[10:13])\n\n[1] 0.03397334\n\n\nA second approach is to add the one-sided p-value + all the probabilities that are less than or equal to the one for the observed table (probabilities for \\(x\\) = 0,1, and 2 in this example; see plot below).\n\n## p-value\nsum(probabilities[10:13]) + sum(probabilities[1:3])\n\n[1] 0.02688011\n\n\n\n## Two-sided test\ncolors &lt;- rep(c('red', 'beige', 'red'), c(3,6,4))\ndf$colors &lt;- colors\n\nggplot(df, aes(x=x, y=p, label=p, fill=colors)) +\n                theme_classic() +\n                geom_bar(stat=\"identity\", fill= colors, colour=\"black\") +\n                geom_text(label=signif(probabilities, 2),\n                                    y=probabilities, size=3, hjust=0.5, vjust=-1) +\n                labs(x = \"Number of BP+ DEGs\", y = \"Probability\")\n\n\n\n\n\n\n\n\nWe get the same result using fisher.test(alternative = ‚Äùtwo.sided‚Äù):\n\nfisher.test(m, alternative = \"two.sided\")   \n\n\n    Fisher's Exact Test for Count Data\n\ndata:  m\np-value = 0.02688\nalternative hypothesis: true odds ratio is not equal to 1\n95 percent confidence interval:\n  1.120742 51.566943\nsample estimates:\nodds ratio \n  6.529133 \n\n\n\n\n\n\n\n\nTipWhat‚Äôs the odds ratio?\n\n\n\n\n\n\n\n\n\nOdds of DE in BP+ genes = \\(\\frac{a_{11}}{a_{21}}\\): how many times it is more likely to be a DEG than a non-DEG among the genes in the functional set.\nOdds of DE in BP- genes =\\(\\frac{a_{12}}{a_{22}}\\): how many times it is more likely to be a DEG than a non-DEG among the genes outside the functional set.\nOdds ratio (OR) of DE in BP+ vs.¬†BP- genes = \\(\\frac{a_{11}}{a_{21}} / \\frac{a_{12}}{a_{22}}\\) = \\(\\frac{a_{11}\\times a_{22}}{a_{12} \\times a_{21}}\\): how many times it is more probable to be a DEG among the BP+ genes than among BP- genes.\n\nSame thing if we interchange the columns and rows:\n\n\n\n\n\n\nOdds of being BP+ in DEGs = \\(\\frac{a_{11}}{a_{12}}\\)\nOdds of being BP+ in non-DEGs = \\(\\frac{a_{21}}{a_{22}}\\)\nOdds ratio = odds of being BP+ in DEGs vs.¬†non-DEGs: \\(\\frac{a_{11}}{a_{12}} / \\frac{a_{21}}{a_{22}}\\) =\\(\\frac{a_{11}\\times a_{22}}{a_{12} \\times a_{21}}\\)\n\nIf OR&gt;1 then it is more likely to be a BP+ gene among the group of DEGs‚Üí positive association between the two variables.\nIf OR&lt;1 then is more likely to be a BP+ gene among the group of non-DEGs‚Üí negative association between the two variables.\nIf OR‚â†1 then is either more or less likely to be a BP+ gene among the group of DEGs ‚Üí there is an association between the two variables.\nThe OR returned by fisher.test() differs slightly from this formula as they are calculated based on the conditional maximum-likelihood estimate."
  },
  {
    "objectID": "posts/2024-10-10-coeffs_linear_models/index.html",
    "href": "posts/2024-10-10-coeffs_linear_models/index.html",
    "title": "Understading coefficients in linear models fits for RNA-seq data",
    "section": "",
    "text": "‚ö†Ô∏è This page is under development.\n\nIntroduction\n\n\nWhat you‚Äôll learn here\n\nHow to interpret the coefficients in the design matrices.\nUnderstand the syntaxis of interaction coefficients and learn how to interpret and utilize them.\n\n\n\n\nAn example data set\nWe‚Äôll use recount3 package to download real gene expression data from a study, including sample metadata and QC metrics that will be helpful to illustrate variable associations with gene expression data.\nThe chosen study can be found in the Sequence Read Archive (SRA) with project ID SRP107565, and is titled ‚ÄúMultiomics Profiling Establishes the Polypharmacology of FDA-Approved CDK4/6 Inhibitors and the Potential for Differential Clinical Activity‚Äù.\n\nlibrary(recount3)\n# \n# ## Download all available projects in human in recount3\n# human_projects &lt;- available_projects()\n# \n# ## Download gene expression data and metadata from \n# proj_info &lt;- subset(\n#     human_projects,\n#     project == \"SRP107565\" & project_type == \"data_sources\"\n# )\n# \n# \n# rse_gene_SRP009615 &lt;- create_rse(project_info)"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#download-data",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#download-data",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "Download data",
    "text": "Download data\nWe‚Äôll use recount3 (Leonardo Collado-Torres 2020; Wilks et al. 2021) package to download real gene expression data from a transcriptomic study, including sample metadata and quality-control (QC) metrics.\nThe chosen study can be found in the Sequence Read Archive (SRA) under ID SRP107565, and it‚Äôs titled ‚ÄúMultiomics Profiling Establishes the Polypharmacology of FDA-Approved CDK4/6 Inhibitors and the Potential for Differential Clinical Activity‚Äù (Marc Hafner et al., 2019).\n\nlibrary(recount3)\n\n## Download all available projects in human in recount3\nhuman_projects &lt;- available_projects()\n\n## Download gene expression data and metadata from SRP107565 study\nproj_info &lt;- subset(\n    human_projects,\n    project == \"SRP107565\" & project_type == \"data_sources\",\n    recount3_url = \"https://sciserver.org/public-data/recount3/data\"\n)\n\nproj_info\n\n    project organism file_source     project_home project_type n_samples\n1 SRP107565    human         sra data_sources/sra data_sources       216\n\n## Create RangedSummarizedExperiment object to handle RNA-seq and sample data \nrse &lt;- create_rse(proj_info)\n\n## Gene expression data in assay(rse): for first 5 genes and 5 samples\nassay(rse)[1:5, 1:5]\n\n                  SRR5579425 SRR5579426 SRR5579433 SRR5579434 SRR5579435\nENSG00000278704.1          0          0          0          0          0\nENSG00000277400.1          0          0          0          0          0\nENSG00000274847.1          0          0          0          0          0\nENSG00000277428.1          0          0          0          0          0\nENSG00000276256.1          0          0          0          0          0\n\n## Sample metadata in colData(rse): for first 6 samples and 3 variables\nhead(colData(rse)[, 1:3])\n\nDataFrame with 6 rows and 3 columns\n             rail_id external_id       study\n           &lt;integer&gt; &lt;character&gt; &lt;character&gt;\nSRR5579425   1000031  SRR5579425   SRP107565\nSRR5579426   1000045  SRR5579426   SRP107565\nSRR5579433   1000255  SRR5579433   SRP107565\nSRR5579434   1000270  SRR5579434   SRP107565\nSRR5579435   1000286  SRR5579435   SRP107565\nSRR5579436   1000301  SRR5579436   SRP107565\n\n## Gene data in rowData(rse): for first 6 genes and 3 variables\nhead(rowData(rse)[, 1:3])\n\nDataFrame with 6 rows and 3 columns\n                    source     type bp_length\n                  &lt;factor&gt; &lt;factor&gt; &lt;numeric&gt;\nENSG00000278704.1  ENSEMBL     gene      2237\nENSG00000277400.1  ENSEMBL     gene      2179\nENSG00000274847.1  ENSEMBL     gene      1599\nENSG00000277428.1  ENSEMBL     gene       101\nENSG00000276256.1  ENSEMBL     gene      2195\nENSG00000278198.1  ENSEMBL     gene      1468"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#study-specifics",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#study-specifics",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "Study specifics",
    "text": "Study specifics"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#study-design-and-objectives",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#study-design-and-objectives",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "Study design and objectives",
    "text": "Study design and objectives\nIn this study, the authors performed transcriptomic, proteomic, and phenotypic assays to compare the activities of 3 inhibitors of cyclin-dependent kinases 4/6 (CDK4/6): abemaciclib, palbociclib, and ribociclib, which are used to treat hormone receptor-positive breast cancer. For our purposes, only transcriptomic data have been downloaded to be explored.\nSpecifically, in the transcriptomic experiment, 7 breast cancer human cell lines were drug-treated with 0.3, 1 OR 3 ¬µM of abemaciclib, palbociclib, OR ribociclib (OR untreated = control = drug concentration of 0 ¬µM), and mRNA sequencing was performed after 6 OR 24 hrs of exposure.\n\n\n\nIlustration taken from Figure 1A in Marc Hafner et al., 2019.\n\n\nExploring the RangedSummarizedExperiment (Martin Morgan 2017; Huber et al. 2015) object rse we just created, we can see we have raw expression data for 63,856 genes across 216 samples.\n\ndim(rse)\n\n[1] 63856   216\n\n\nProcessing a little the sample attributes contained in sra.sample_attributes variable, we can check the number of samples from each cell line, treated with each drug, at each concentration, and time. Let‚Äôs add individual columns in the sample metadata for these variables.\n\nlibrary(tidyr)\n\n\nAttaching package: 'tidyr'\n\n\nThe following object is masked from 'package:S4Vectors':\n\n    expand\n\n## Sample attributes\nhead(rse$sra.sample_attributes, 3)\n\n[1] \"agent;;Abemaciclib|cell line;;BT20|dose;;0.3 uM|source_name;;BT20 breast cancer cell line|time;;6 hr\"\n[2] \"agent;;Abemaciclib|cell line;;BT20|dose;;0.3 uM|source_name;;BT20 breast cancer cell line|time;;6 hr\"\n[3] \"agent;;Palbociclib|cell line;;BT20|dose;;3 uM|source_name;;BT20 breast cancer cell line|time;;6 hr\"  \n\n## Divide each string by \"|\" and extract drug\nrse$Drug = sapply(rse$sra.sample_attributes, function(x){strsplit(strsplit(x, \"\\\\|\")[[1]][1], \";;\")[[1]][2]}) %&gt;% unname\n\n## Num of samples treated with each drug\ntable(rse$Drug)\n\n\nAbemaciclib     Control Palbociclib  Ribociclib \n         84          28          52          52 \n\n## Num of samples of each cell line\nrse$Cell_line = sapply(rse$sra.sample_attributes, function(x){strsplit(strsplit(x, \"\\\\|\")[[1]][2], \";;\")[[1]][2]}) %&gt;% unname\n\ntable(rse$Cell_line)\n\n\n   BT20   BT549 HCC1419 HCC1806  HS578T    MCF7    T47D \n     32      32      32      32      32      24      32 \n\n## Num of samples treated with each dose\nrse$Concentration =  sapply(rse$sra.sample_attributes, function(x){strsplit(strsplit(x, \"\\\\|\")[[1]][3], \";;\")[[1]][2]}) %&gt;% unname\n\ntable(rse$Concentration)\n\n\n  0 uM 0.3 uM   1 uM   3 uM \n    28     80      4    104 \n\n## Num of samples sequenced after each time\nrse$Time =  sapply(rse$sra.sample_attributes, function(x){strsplit(strsplit(x, \"\\\\|\")[[1]][5], \";;\")[[1]][2]}) %&gt;% unname\n\ntable(rse$Time)\n\n\n24 hr  6 hr \n  108   108"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#data-variables",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#data-variables",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "Data variables",
    "text": "Data variables\nThe following are quality control metrics collected in recount3"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html",
    "href": "posts/2024-12-12-QC_and_EDA/index.html",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "",
    "text": "‚ö†Ô∏è This page is under development."
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#study-design-and-aims",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#study-design-and-aims",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "Study design and aims",
    "text": "Study design and aims\nIn this study, the authors performed transcriptomic, proteomic, biochemical, and phenotypic assays to compare the activities of 3 inhibitors of cyclin-dependent kinases 4/6 (CDK4/6): abemaciclib, palbociclib, and ribociclib, which are used to treat hormone receptor-positive breast cancer. For our purposes, only transcriptomic data have been downloaded to be explored.\nSpecifically, in the transcriptomic experiment, 7 breast cancer human cell lines were drug-treated with 0.3, 1 OR 3 ¬µM of abemaciclib, palbociclib, OR ribociclib (OR untreated = control = drug concentration of 0 ¬µM), and mRNA sequencing was performed after 6 OR 24 hrs of exposure. Including replicates, a total of 216 bulk samples were sequenced.\n\n\n\nIlustration taken from Figure 1A in Marc Hafner et al., 2019.\n\n\nExploring the RangedSummarizedExperiment (Martin Morgan 2017; Huber et al. 2015) object (rse) we just created, we can see we have raw expression data for 63,856 genes across 216 samples.\n\ndim(rse)\n\n[1] 63856   216\n\n\nProcessing the sample attributes contained in sra.sample_attributes, we can check the number of samples from each cell line, treated with each drug, at each concentration, and time. Let‚Äôs add individual columns in the sample metadata for these variables.\n\nlibrary(tidyr)\n\n## Sample attributes\nhead(rse$sra.sample_attributes, 3)\n\n[1] \"agent;;Abemaciclib|cell line;;BT20|dose;;0.3 uM|source_name;;BT20 breast cancer cell line|time;;6 hr\"\n[2] \"agent;;Abemaciclib|cell line;;BT20|dose;;0.3 uM|source_name;;BT20 breast cancer cell line|time;;6 hr\"\n[3] \"agent;;Palbociclib|cell line;;BT20|dose;;3 uM|source_name;;BT20 breast cancer cell line|time;;6 hr\"  \n\n## Divide each string by \"|\" and extract drug\nrse$Drug = sapply(rse$sra.sample_attributes, function(x){strsplit(strsplit(x, \"\\\\|\")[[1]][1], \";;\")[[1]][2]}) %&gt;% unname\n\n## Num of samples treated with each drug\ntable(rse$Drug)\n\n\nAbemaciclib     Control Palbociclib  Ribociclib \n         84          28          52          52 \n\n## Num of samples of each cell line\nrse$Cell_line = sapply(rse$sra.sample_attributes, function(x){strsplit(strsplit(x, \"\\\\|\")[[1]][2], \";;\")[[1]][2]}) %&gt;% unname\n\ntable(rse$Cell_line)\n\n\n   BT20   BT549 HCC1419 HCC1806  HS578T    MCF7    T47D \n     32      32      32      32      32      24      32 \n\n## Num of samples treated with each dose\nrse$Concentration =  sapply(rse$sra.sample_attributes, function(x){strsplit(strsplit(x, \"\\\\|\")[[1]][3], \";;\")[[1]][2]}) %&gt;% unname\n\ntable(rse$Concentration)\n\n\n  0 uM 0.3 uM   1 uM   3 uM \n    28     80      4    104 \n\n## Num of samples sequenced after each time\nrse$Time =  sapply(rse$sra.sample_attributes, function(x){strsplit(strsplit(x, \"\\\\|\")[[1]][5], \";;\")[[1]][2]}) %&gt;% unname\n\ntable(rse$Time)\n\n\n24 hr  6 hr \n  108   108"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#sample-variables",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#sample-variables",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "Sample variables",
    "text": "Sample variables\nIn any EDA, we first need to know what the sample variables in the metadata stand for in order to interpret accurately any insights derived from them. A second important consideration is that, even when there are well-established QC metrics used to filter samples, exploring a broader set of them is convenient to find unexpected sample quality differences.\nWe start by defining the sample-level variables we‚Äôll explore in our EDA.\n\nMain sample attributes\n\nCell_line: name of breast cancer cell line.\nDrug: the drug with which a given cell line was treated.\nConcentration: the concentration of the drug administered to the cell line.\nTime: drug exposure time for each cell line.\n\n\n\nQuality-control metrics\nQC metrics are measurements of a sample‚Äôs RNA composition and the mapping of its reads to a reference genome, reflecting the integrity of the cells, and the quality of the mRNA extraction, library preparation, sequencing, and read alignment steps.\nThe following metrics were collected by recount3 through a number of tools.\n\nAlignment-related metrics obtained through STAR (Dobin et al. 2012):\n\nall_mapped_reads: total number of aligned reads aligned.\nuniquely_mapped_reads_%: number of reads that mapped to a single locus, of the total input reads.\nuniquely_mapped_reads_number: number of reads that mapped to a single locus.\n%_of_reads_mapped_to_multiple_loci: number of reads that mapped to multiple loci, of the input reads.\nnumber_of_reads_mapped_to_multiple_loci: number of reads that mapped to multiple loci.\n%_of_reads_unmapped:_other: reads that didn‚Äôt map due to no acceptable seed/windows, of all input reads.\nnumber_of_reads_unmapped:_other: number of reads left unmapped due to no acceptable seed/windows.\n%_of_reads_unmapped:_too_many_mismatches: Number of reads where best alignment has more mismatches than max allowed number of mismatches divided by number of input reads\nnumber_of_reads_unmapped:_too_many_mismatches: Number of reads where best alignment has more mismatches than max allowed number of mismatches\n%_of_reads_unmapped:_too_short: Number of reads where best alignment was shorter than min allowed mapped length divided by number of input reads.\nnumber_of_reads_unmapped:_too_short: Number of reads where best alignment was shorter than min allowed mapped length.\n\nSAMtools (Danecek et al. 2021) statistics for chromosome-specific read mapping. Of special interest are the reads mapping to the mitochondrial and sex chromosomes (see explanation in Step X):\n\naligned_reads%.chrm: Percent of reads aligning to the mitochondrial genome.\naligned_reads%.chrx: Percent of reads aligning to chromosome X.\naligned_reads%.chry: Precent of reads aligning to chromosome Y.\n\nSequencing coverage summaries in gene annotations by megadepth (bc) (Wilks et al. 2020) and featureCounts (Liao, Smyth, and Shi 2013) (fc):\n\nbc_auc.all_reads_all_bases: Area under coverage (total depth of coverage evaluated at all bases) for all alignments\nbc_auc.all_reads_annotated_bases: Area under coverage for all alignments, but only for bases in annotated exons\nbc_auc.unique_reads_all_bases: Area under coverage for uniquely aligned reads\nbc_auc.unique_reads_annotated_bases: Area under coverage for uniquely aligned reads, but only for bases in annotated exons.\nexon_fc_count_all.total: Total number of fragments, including multi-mappers, input to¬†featureCounts\nexon_fc_count_all.assigned: Number of fragments, including multi-mappers, assigned by¬†featureCounts¬†to an exon\nexon_fc_count_unique.total: Total number of uniquely mapping fragments input to¬†featureCounts\nexon_fc_count_unique.assigned: Number of uniquely mapping fragments assigned by¬†featureCounts¬†to an exon.\ngene_fc_count_all.total: Total number of fragments, including multi-mappers, input to¬†featureCounts\ngene_fc_count_all.assigned: Number of fragments, including multi-mappers, assigned by¬†featureCounts¬†to a gene\ngene_fc_count_unique.total: Total number of uniquely mapping fragments input to¬†featureCounts\ngene_fc_count_unique.assigned: Number of uniquely mapping fragments assigned by¬†featureCounts¬†to a gene.\n\n\nFor more details on the computation of these metrics please refer to recount3 documentation and the manual of each tool."
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#section",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#section",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "3.1",
    "text": "3.1\n3.2 Explore sex differenes: sexual chr % can be helpful in, for instance, confirming the sex of the individual sequenced based on alignments to sex chromosomes"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#explore-differences-in-qc-metrics-between-sample-groups",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#explore-differences-in-qc-metrics-between-sample-groups",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "3.1 Explore differences in QC metrics between sample groups",
    "text": "3.1 Explore differences in QC metrics between sample groups\nExplore sex differences: sexual chr % can help to confirm the sex of the donors based on alignments to sex chromosomes.\nhttps://frontlinegenomics.com/how-to-ngs-quality-control/\nhttps://www.nature.com/articles/s41592-023-01946-4"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#explore-relationships-between-sample-variables",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#explore-relationships-between-sample-variables",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "3.2 Explore relationships between sample variables",
    "text": "3.2 Explore relationships between sample variables"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#identify-sample-outliers-boxplots-and-pca",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#identify-sample-outliers-boxplots-and-pca",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "3.3 Identify sample outliers (Boxplots and PCA)",
    "text": "3.3 Identify sample outliers (Boxplots and PCA)"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#dimensionality-reduction",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#dimensionality-reduction",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "4.1 Dimensionality reduction",
    "text": "4.1 Dimensionality reduction"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#correlation-between-variables",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#correlation-between-variables",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "4.2 Correlation between variables",
    "text": "4.2 Correlation between variables"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#partition-of-gene-expression-variance",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#partition-of-gene-expression-variance",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "4.2 Partition of gene expression variance",
    "text": "4.2 Partition of gene expression variance"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#read-count-distribution",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#read-count-distribution",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "1.1 Read count distribution",
    "text": "1.1 Read count distribution\nA first simple but very informative plot is an histogram of the raw counts, before any transformation. This gives us an idea of how sparse the data are, i.e., if a large percentage of the counts are zero.\n\nlibrary(\"ggplot2\")\n\n## Raw counts\ndata &lt;- data.frame(raw_counts = as.vector(assays(rse)$raw_counts))\nplot &lt;- ggplot(data, aes(x = raw_counts)) +\n    geom_histogram(colour = \"black\", fill = \"lightgray\") +\n    labs(x = \"Raw counts\", y = \"Frecuency\") +\n    theme_classic()\nplot + theme(plot.margin = unit(c(2, 4, 2, 4), \"cm\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n## Percentage of counts that are zero\nlength(which(as.vector(assays(rse)$raw_counts) == 0)) / length(as.vector(assays(rse)$raw_counts)) * 100\n\n[1] 61.05911\n\n\nMore than 60% of the total counts across all genes and samples are 0. This is not surprising as we expect most genes not to be highly expressed in every condition. But is this true for all samples? Are there samples with susbtantially more expressed genes than others?\nExamining the expression of genes in each sample is relevant because it offers insights about the RNA composition of the samples, which"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html",
    "href": "posts/2024-12-15-TMM_normalization/index.html",
    "title": "Trimmed Mean of M-values",
    "section": "",
    "text": "Normalization is a critical processing step in RNA-seq data analysis. By normalizing raw read counts generated through transcriptomics assays, we reduce the systematic effects that technical within- and between-samples differences have on the data, making the expression measurements more comparable across genes and samples, and enabling the study of transcriptome dynamics.\nVarying sequencing depth among the samples is usually accounted for in normalization methods, where gene counts are scaled by sample library size (i.e.¬†total sum of read counts per sample). This consideration is necessary when comparing expression levels between samples but is not the only factor at play, specially when samples are expected to have very variable transcriptome sizes across experimental conditions.\nIn a pioneer paper of 2010, Mark D. Robinson and Alicia Oshlack introduced the issue of the RNA composition bias in RNA-seq data, and developed the Trimmed Mean of M-values (TMM) method to adjust for it. As a widely-implemented normalization scheme, it is important to understand why sample RNA population differences are a concern for normalization and how TMM accounts for it."
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#counts-per-million",
    "href": "posts/2024-12-15-TMM_normalization/index.html#counts-per-million",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "Counts per million",
    "text": "Counts per million"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#tmm",
    "href": "posts/2024-12-15-TMM_normalization/index.html#tmm",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "TMM",
    "text": "TMM\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC2864565/pdf/gb-2010-11-3-r25.pdf"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#cpm-cuttoff",
    "href": "posts/2024-12-15-TMM_normalization/index.html#cpm-cuttoff",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "CPM cuttoff",
    "text": "CPM cuttoff"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#filterbyexpr",
    "href": "posts/2024-12-15-TMM_normalization/index.html#filterbyexpr",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "filterByExpr",
    "text": "filterByExpr"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#qc-metrics-based-on-rawlog-normalized-counts",
    "href": "posts/2024-12-15-TMM_normalization/index.html#qc-metrics-based-on-rawlog-normalized-counts",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "QC metrics based on raw/log-normalized counts",
    "text": "QC metrics based on raw/log-normalized counts"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#qc-metrics-based-on-allexpressed-genes",
    "href": "posts/2024-12-15-TMM_normalization/index.html#qc-metrics-based-on-allexpressed-genes",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "QC metrics based on all/expressed genes",
    "text": "QC metrics based on all/expressed genes\nSamples are required in the filtering process and in TMM (sample vs sample comparison; in CPM library sizes are computed independently)\nFor sample outlier detection we run PCA with normalized and filtered counts.\nIt depends on if we have prior knowledge of the samples quality and if those QC metrics that are outliers imply that the RNA composition is atypical or problematic: we can plot that and compare. If there are few samples they are not likely to affect downstream results."
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#read-count-distribution-todo",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#read-count-distribution-todo",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "1.1 Read count distribution TODO",
    "text": "1.1 Read count distribution TODO\nA first thing to plot is the frequency of the raw counts across all genes and samples, before any transformation. This gives us an idea of how sparse the data are, i.e., if a large percentage of the counts are zero.\n\nlibrary(\"ggplot2\")\n\n## Raw counts\ndata &lt;- data.frame(raw_counts = as.vector(assays(rse)$raw_counts))\nplot &lt;- ggplot(data, aes(x = raw_counts)) +\n    geom_histogram(colour = \"black\", fill = \"lightgray\") +\n    labs(x = \"Raw counts\", y = \"Frecuency\") +\n    theme_classic()\nplot + theme(plot.margin = unit(c(2, 4, 2, 4), \"cm\"))\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n\n\n\n\n\n\n\n\n## Percentage of counts that are zero\nlength(which(as.vector(assays(rse)$raw_counts) == 0)) / length(as.vector(assays(rse)$raw_counts)) * 100\n\n[1] 61.05911\n\n\nMore than 60% of the total counts across all genes and bulk samples are 0. Even though this is a large fraction, it is not surprising as we don‚Äôt expect most genes to be expressed in every condition; scRNA-seq data is even more sparse. In step 1.3 we‚Äôll deal with lowly-expressed genes ‚Ä¶"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#count-log-normalization-todo",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#count-log-normalization-todo",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "1.2 Count log-normalization TODO",
    "text": "1.2 Count log-normalization TODO"
  },
  {
    "objectID": "posts/2024-12-12-QC_and_EDA/index.html#filtering-lowly-expressed-genes-todo",
    "href": "posts/2024-12-12-QC_and_EDA/index.html#filtering-lowly-expressed-genes-todo",
    "title": "Exploratory Data Analysis for RNA-seq data",
    "section": "1.3 Filtering lowly-expressed genes TODO",
    "text": "1.3 Filtering lowly-expressed genes TODO\nThere are multiple approaches to remove zero- and lowly-expressed genes. Here we‚Äôll adopt the approach of removing genes with less than X CPM in at least X % samples ‚Ä¶\nhttps://carpentries-incubator.github.io/rna-seq-data-for-ml/episode5.html"
  },
  {
    "objectID": "posts/2024-01-20_Filtering_and_Normalization/index.html",
    "href": "posts/2024-01-20_Filtering_and_Normalization/index.html",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "",
    "text": "‚ö†Ô∏è This page is under development."
  },
  {
    "objectID": "posts/2024-01-20_Filtering_and_Normalization/index.html#counts-per-million",
    "href": "posts/2024-01-20_Filtering_and_Normalization/index.html#counts-per-million",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "Counts per million",
    "text": "Counts per million"
  },
  {
    "objectID": "posts/2024-01-20_Filtering_and_Normalization/index.html#tmm",
    "href": "posts/2024-01-20_Filtering_and_Normalization/index.html#tmm",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "TMM",
    "text": "TMM\nhttps://pmc.ncbi.nlm.nih.gov/articles/PMC2864565/pdf/gb-2010-11-3-r25.pdf"
  },
  {
    "objectID": "posts/2024-01-20_Filtering_and_Normalization/index.html#cpm-cuttoff",
    "href": "posts/2024-01-20_Filtering_and_Normalization/index.html#cpm-cuttoff",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "CPM cuttoff",
    "text": "CPM cuttoff"
  },
  {
    "objectID": "posts/2024-01-20_Filtering_and_Normalization/index.html#filterbyexpr",
    "href": "posts/2024-01-20_Filtering_and_Normalization/index.html#filterbyexpr",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "filterByExpr",
    "text": "filterByExpr"
  },
  {
    "objectID": "posts/2024-01-20_Filtering_and_Normalization/index.html#qc-metrics-based-on-rawlog-normalized-counts",
    "href": "posts/2024-01-20_Filtering_and_Normalization/index.html#qc-metrics-based-on-rawlog-normalized-counts",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "QC metrics based on raw/log-normalized counts",
    "text": "QC metrics based on raw/log-normalized counts"
  },
  {
    "objectID": "posts/2024-01-20_Filtering_and_Normalization/index.html#qc-metrics-based-on-allexpressed-genes",
    "href": "posts/2024-01-20_Filtering_and_Normalization/index.html#qc-metrics-based-on-allexpressed-genes",
    "title": "What comes first: count normalization or gene/sample filtering?",
    "section": "QC metrics based on all/expressed genes",
    "text": "QC metrics based on all/expressed genes\nSamples are required in the filtering process and in TMM (sample vs sample comparison; in CPM library sizes are computed independently)\nFor sample outlier detection we run PCA with normalized and filtered counts.\nIt depends on if we have prior knowledge of the samples quality and if those QC metrics that are outliers imply that the RNA composition is atypical or problematic: we can plot that and compare. If there are few samples they are not likely to affect downstream results."
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#the-rna-composition-bias",
    "href": "posts/2024-12-15-TMM_normalization/index.html#the-rna-composition-bias",
    "title": "Trimmed Mean of M values",
    "section": "The RNA composition bias",
    "text": "The RNA composition bias\nThis sampling introduces a proportionality problem in the RNA-seq count data: in those samples with more highly-expressed genes (and thus more transcripts), a higher proportion of reads will come from such genes, taking away reads for all the other genes and apparently reducing their expression. Therefore, we need to account for the proportion of reads mapping to each gene after ‚Äúsampling‚Äù.\nIn the next code we randomly select 1000 reads per sample and plot the proportion that correspond to each gene per sample.\n\nlibrary(Polychrome)\n\n## Create pool of reads per gene in each sample\ncolnames(expr) &lt;- library_sizes$sample\nreads_per_gene_per_sample &lt;- apply(expr, 2, function(sample) {rep(rownames(expr), sample)})\n\n## Randomly select 1000 reads per sample\nset.seed(12242024)\nreads_sample &lt;- lapply(reads_per_gene_per_sample, function(sample) {sample(sample, size = 1000, replace = FALSE)})\n\n## Read counts per gene after sampling\nrna_seq_expr &lt;- lapply(reads_sample, function(sample){table(sample)[rownames(expr)]})\n# lapply(rna_seq_expr, function(x){which(is.na(names(x)))})\n\nrna_seq_expr &lt;- do.call(cbind, lapply(reads_sample, table))\nrna_seq_expr &lt;- rna_seq_expr[rownames(expr), ]\nrna_seq_expr_melted &lt;- melt(rna_seq_expr)\ncolnames(rna_seq_expr_melted) &lt;- c(\"gene\", \"sample\", \"count\")\nrna_seq_expr_melted &lt;- merge(rna_seq_expr_melted, library_sizes[, c(\"sample\", \"Condition\")], by = \"sample\")\n\n## Order genes for plotting\nrna_seq_expr_melted$gene &lt;- factor(rna_seq_expr_melted$gene, levels = paste(\"gene\", 1:30))\n\n## Color palette for genes\nset.seed(12212024)\ncol_palette &lt;- sample(c(hcl.colors(30, palette = \"Pastel 1\"), \n                        hcl.colors(30, palette = \"PinkYl\"),\n                        hcl.colors(30, palette = \"Cyan-Magenta\")), 30, replace = F)\nnames(col_palette) &lt;- rownames(expr)\ncol_palette[paste(\"gene\", 5:7)] &lt;- c(\"orangered\", \"yellow3\", \"mediumpurple1\")\n  \n## Bar plot\nggplot(data = rna_seq_expr_melted, aes(x = sample, y = count, fill = gene, alpha = gene)) + \n  geom_bar(stat = \"identity\", colour = \"black\", linewidth = 0.2) +\n  theme_bw() + \n  labs(x = \"\", y = \"Read per gene after sampling\", fill = \"Gene\") + \n  scale_fill_manual(values = col_palette) +\n  scale_alpha_manual(values = rep(c(0.7, 1, 0.7), c(4, 3, 23))) +\n  guides(alpha = \"none\") +\n  theme(axis.text.x = element_text(size = 8, angle = 45, hjust = 1), \n        legend.title = element_text(face = \"bold\", size = 10), \n        legend.text = element_text(size = 8), \n        legend.key.width = unit(0.35, \"cm\"),\n        legend.key.height = unit(0.35, \"cm\"))\n\n\n\n\n\n\n\n\nClearly, in samples of condition A most of the reads go to the highly-expressed genes 5, 6, and 7, and the reads for the rest of genes are decreased, compared to the other samples with similar read proportions across genes. In the following heat map of counts after sampling, note the reduced expression of all non highly-expressed expressed genes in condition A, while maintaining similar low expression levels for all genes in conditions B and C.\n\ncolnames(rna_seq_expr) &lt;- conditions\n\n## Plot heat map\ncol_anno &lt;- HeatmapAnnotation(\n  Condition = anno_block(gp = gpar(fill = c(\"orchid1\", \"palegreen1\", \"deepskyblue1\"), col = \"black\"), show_name = T), \n  annotation_name_gp =  gpar(fontsize = 9, fontface = \"bold\"))\n\nHeatmap(rna_seq_expr,\n        name = \"RNA-seq counts\", \n        top_annotation = col_anno, \n        cluster_rows = FALSE,\n        cluster_columns = FALSE,\n        col = colorRamp2(c(1, 10, 100, 2000), c(\"linen\", \"mistyrose2\", \"rosybrown2\", \"darkred\")),\n        column_split = conditions,\n        border = TRUE,\n        show_row_names = TRUE,\n        column_title = \"Samples\",\n        column_title_gp = gpar(fontsize = 10, fontface = \"bold\"),\n        column_names_side = \"top\",\n        column_names_gp = gpar(fontsize = 9, fontface = \"bold\"),\n        row_names_gp = gpar(fontsize = 8),\n        row_names_side = \"left\",\n        column_names_rot = 0,\n        heatmap_width = unit(12.5, \"cm\"),\n        heatmap_height = unit(12.5, \"cm\")\n)"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#more-false-positives",
    "href": "posts/2024-12-15-TMM_normalization/index.html#more-false-positives",
    "title": "Trimmed Mean of M values",
    "section": "More false positives ‚Ä¶",
    "text": "More false positives ‚Ä¶\nMore false positives.\n\n## Matrices to save gene p-values and t-stats\npvals &lt;- matrix(data = NA, nrow = nrow(rna_seq_expr), ncol = 3)\ntstats &lt;- matrix(data = NA, nrow = nrow(rna_seq_expr), ncol = 3)\n\ncolnames(pvals) &lt;- colnames(tstats)  &lt;- c(\"A_vs_B\",  \"A_vs_C\",  \"B_vs_C\")\nrownames(pvals) &lt;- rownames(tstats) &lt;- paste0(\"gene\", 1:30)\n\n\n## Iterate over genes\nfor(i in 1:nrow(rna_seq_expr)){\n  \n  ## t-test for gene expr in condition1 vs condition2\n  for(condition_pair in list(c(\"A\", \"B\"),  c(\"A\", \"C\"),  c(\"B\", \"C\"))){\n    \n    comparison &lt;- paste0(condition_pair[1], \"_vs_\", condition_pair[2])\n    gene &lt;- paste0(\"gene\", i)\n    \n    gene_expr &lt;- rna_seq_expr[i, colnames(rna_seq_expr) %in% condition_pair]\n    formula &lt;- gene_expr ~ Condition\n    results &lt;- t.test(formula = formula, \n                      data = data.frame(\"Condition\" = conditions[conditions %in% condition_pair]))\n    \n    pvals[gene, comparison] &lt;- results$p.value\n    tstats[gene, comparison] &lt;- results$statistic\n\n  }\n  \n}\n\n## Plot t-stats \nmelted_pvals = melt(pvals)\nmelted_tstats = melt(tstats)\n\ndata = cbind(melted_pvals, melted_tstats$value)\ncolnames(data) &lt;- c(\"gene\", \"comparison\", \"p\", \"t\")\ndata$signif &lt;- sapply(data$p, function(p){ if(p&lt;0.05){\"*\"} else{NA}})\n\nggplot(data, aes(x = gene, y = t, fill = comparison, color = comparison)) + \n  geom_bar(stat = \"identity\", position=\"dodge\", colour = \"black\", width = 0.65, linewidth = 0.3) +\n  geom_text(aes(x = gene, y = t + (sign(t)), label = signif, \n                group = comparison, color = comparison), \n            position = position_dodge(0.9), hjust = 0.5,\n            show.legend = F) +\n  theme_bw() + \n  labs(x = \"\", y = \"Change in expression\", fill = \"Comparison\") + \n  scale_fill_manual(values = c(\"A_vs_B\" = \"#8DB6CD\", \n                               \"A_vs_C\" = \"#FF82AB\", \n                               \"B_vs_C\" = \"#A2CD5A\"), \n                               labels = c(\"A vs B\", \"A vs C\", \"B vs C\")) +\n  scale_color_manual(values = c(\"A_vs_B\" = \"#8DB6CD\", \n                                \"A_vs_C\" = \"#FF82AB\", \n                                \"B_vs_C\" = \"#A2CD5A\")) +\n  theme(axis.text.x = element_text(size = 6, angle = 45, hjust = 1), \n        axis.title.y = element_text(size = 8), \n        axis.text.y = element_text(size = 6), \n        legend.title = element_text(face = \"bold\", size = 7), \n        legend.text = element_text(size = 6), \n        legend.key.width = unit(0.3, \"cm\"),\n        legend.key.height = unit(0.3, \"cm\"))"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#hypothetical-scenario",
    "href": "posts/2024-12-15-TMM_normalization/index.html#hypothetical-scenario",
    "title": "Trimmed Mean of M values",
    "section": "Hypothetical scenario",
    "text": "Hypothetical scenario\nImagine we have 15 samples across 3 experimental conditions (A, B, and C), each containing all the transcripts expressed from 30 genes with the same length. Suppose all transcripts in each sample are sequenced, without restricting the number of sequenced molecules per library. This artificial scenario would result in sequencing reads for all transcripts per gene, thus serving as estimates of true expression*.\nThen, think of the following three cases:\n\nCase 1: Highly-expressed genes in one condition only:\nOf the 30 genes, 27 have similar expression levels in all three conditions, and 3 are more highly-expressed in condition A than in B and C(genes 5, 6, and 7).\n\n\n\n\n\n\nBelow, we create a matrix of the raw read counts (ranging from 10 to 100) for all 30 genes across the 15 samples. Then, we introduce the 3 highly-expressed genes (counts from 1,000 to 2,000) in condition A only.\n\nlibrary(ComplexHeatmap)\nlibrary(circlize)\n\n## 15 samples across 3 conditions \nconditions &lt;- rep(c(\"A\", \"B\", \"C\"), c(4, 5, 6))\n\n################################################################\n##                           Case 1:\n################################################################\n\n## Raw counts from 10-100 for 30 genes across the 15 samples\nset.seed(12242024)\nexpr_case1 &lt;- matrix(data = sample(c(10:100), replace = T, size = 450), nrow = 30)\ncolnames(expr_case1) &lt;- conditions\nrownames(expr_case1) &lt;- paste(\"gene\", 1:30)\n\n## Introduce the 3 highly-expressed genes in condition A \nexpr_case1[c(\"gene 5\", \"gene 6\", \"gene 7\"), 1:4] &lt;- sample(c(1000:2000), replace = T, size = 12)\n\n\n## Heat map\ncol_anno &lt;- HeatmapAnnotation(\n  Condition = anno_block(gp = gpar(fill = c(\"orchid1\", \"palegreen1\", \"deepskyblue1\"), \n                                   col = \"black\"), show_name = T), \n  annotation_name_gp =  gpar(fontsize = 9, fontface = \"bold\"))\n\nHeatmap(expr_case1,\n        name = \"Raw counts\", \n        top_annotation = col_anno, \n        col = colorRamp2(c(1, 10, 100, 2000), \n                         c(\"linen\", \"mistyrose2\", \"rosybrown2\", \"darkred\")),\n        cluster_rows = FALSE,\n        cluster_columns = FALSE,\n        column_split = conditions,\n        column_title = \"Samples\",\n        column_title_gp = gpar(fontsize = 10, fontface = \"bold\"),\n        column_names_side = \"top\",\n        column_names_gp = gpar(fontsize = 9, fontface = \"bold\"),\n        column_names_rot = 0,\n        show_row_names = TRUE,\n        row_names_gp = gpar(fontsize = 8),\n        row_names_side = \"left\",\n        border = TRUE,\n        heatmap_width = unit(12.5, \"cm\"),\n        heatmap_height = unit(12.5, \"cm\")\n)\n\n\n\n\n\n\n\n\n\nCase 2: Genes expressed uniquely in one condition:\nOf the 30 genes, 15 are similarly expressed across the three conditions (genes 1-15), and the second half of genes (genes 16-30) are uniquely expressed in condition A but to the same extent as the other genes. Thus, samples of condition A have twice the number of expressed genes in B and C samples.\n\n################################################################\n##                           Case 2:\n################################################################\n\n## 15 genes similarly expressed in all samples\nset.seed(12242024)\nexpr_case2 &lt;- matrix(data = sample(c(10:100), replace = T, size = 225), nrow = 15)\ncolnames(expr_case2) &lt;- conditions\n\n## 15 genes expressed in condition A samples only\nexpr_case2 &lt;- rbind(expr_case2, \n              cbind(matrix(sample(c(10:100), replace = T, size = 60), nrow = 15), \n                    matrix(0, nrow = 15, ncol = 11))\n              )\nrownames(expr_case2) &lt;- paste(\"gene\", 1:30)\n\n## Heat map\nHeatmap(expr_case2,\n        name = \"Raw counts\", \n        top_annotation = col_anno, \n        col = colorRamp2(c(0, 1, 10, 100, 2000), \n                         c(\"gray95\", \"linen\", \"mistyrose2\", \"rosybrown2\", \"darkred\")),\n        cluster_rows = FALSE,\n        cluster_columns = FALSE,\n        column_split = conditions,\n        column_title = \"Samples\",\n        column_title_gp = gpar(fontsize = 10, fontface = \"bold\"),\n        column_names_side = \"top\",\n        column_names_gp = gpar(fontsize = 9, fontface = \"bold\"),\n        column_names_rot = 0,\n        show_row_names = TRUE,\n        row_names_gp = gpar(fontsize = 8),\n        row_names_side = \"left\",\n        border = TRUE,\n        heatmap_width = unit(12.5, \"cm\"),\n        heatmap_height = unit(12.5, \"cm\")\n)\n\n\n\n\n\n\n\n\nCase 3: Highly-expressed genes uniquely in one condition:\nOf the 30 genes, 27 have similar expression levels in all 3 conditions, and 3 are uniquely expressed in condition A and are more high-expressed than the rest of genes (genes 28, 19, and 30).\n\n################################################################\n##                           Case 3:\n################################################################\n\n## 27 similarly expressed genes in all samples\nset.seed(12242024)\nexpr_case3 &lt;- matrix(data = sample(c(10:100), replace = T, size = 405), nrow = 27)\ncolnames(expr_case3) &lt;- conditions\n\n## Add the 3 highly-expressed genes in condition A only\nexpr_case3 &lt;- rbind(expr_case3, \n              cbind(matrix(sample(c(1000:2000), replace = T, size = 12), nrow = 3), \n                    matrix(0, nrow = 3, ncol = 11))\n              )\nrownames(expr_case3) &lt;- paste(\"gene\", 1:30)\n\n## Heat map\nHeatmap(expr_case3,\n        name = \"Raw counts\", \n        top_annotation = col_anno, \n        col = colorRamp2(c(0, 1, 10, 100, 2000), \n                         c(\"gray95\", \"linen\", \"mistyrose2\", \"rosybrown2\", \"darkred\")),\n        cluster_rows = FALSE,\n        cluster_columns = FALSE,\n        column_split = conditions,\n        column_title = \"Samples\",\n        column_title_gp = gpar(fontsize = 10, fontface = \"bold\"),\n        column_names_side = \"top\",\n        column_names_gp = gpar(fontsize = 9, fontface = \"bold\"),\n        column_names_rot = 0,\n        show_row_names = TRUE,\n        row_names_gp = gpar(fontsize = 8),\n        row_names_side = \"left\",\n        border = TRUE,\n        heatmap_width = unit(12.5, \"cm\"),\n        heatmap_height = unit(12.5, \"cm\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n*The number of reads mapping to a given gene depends on gene expression (number of gene transcripts), but also gene length: larger genes will have more mapping reads. Thus, read counts are not direct estimations of gene expression. In our examples, however, we assumed all genes have the same length so that reads counts reflect expression."
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#transcriptomes-that-are-naturally-different",
    "href": "posts/2024-12-15-TMM_normalization/index.html#transcriptomes-that-are-naturally-different",
    "title": "Trimmed Mean of M-values",
    "section": "Transcriptomes that are naturally different",
    "text": "Transcriptomes that are naturally different\nSomething perhaps evident but worth showing is that the sizes of the ‚Äútrue‚Äù total libraries we just generated, vary considerably between samples in these three hypothetical but not unlikely scenarios. In all cases, samples in condition A have greater library sizes because of highly-expressed genes in Case 1, more expressed genes in Case 2, or both in Case 3, as presented in the below bar plots.\n\n\nShow code\nlibrary(ggplot2)\n\n## Sample library sizes and conditions\nlibrary_sizes &lt;- data.frame(\"lib_size_case1\" = apply(expr_case1, 2, sum),\n                            \"lib_size_case2\" = apply(expr_case2, 2, sum),\n                            \"lib_size_case3\" = apply(expr_case3, 2, sum),\n                            \"sample\" = paste(\"sample\", 1:15),\n                            \"Condition\" = conditions)\n\n## Order samples for plotting\nlibrary_sizes$sample &lt;- factor(library_sizes$sample, levels = unique(library_sizes$sample))\n\n## Bar plot for library sizes in each case \nfor(case in 1:3){\n  \n  ## args for adding numbers\n  ynum &lt;- ifelse(case == 2, 60, 200)\n\n  plot &lt;- ggplot(data = library_sizes, \n                 aes(x = sample, \n                     y = .data[[paste0(\"lib_size_case\", case)]], \n                     fill = Condition)) + \n    geom_bar(stat = \"identity\", colour = \"black\") + \n    geom_text(aes(y = .data[[paste0(\"lib_size_case\", case)]] + ynum, \n                  label = .data[[paste0(\"lib_size_case\", case)]]), size = 3) +\n    theme_bw() + \n    labs(title = paste(\"Case\", case, \"library sizes\"), x = \"\", y = \"Total read counts\") + \n    scale_fill_manual(values = c(\"A\" = \"orchid1\", \"B\" = \"palegreen1\", \"C\" = \"deepskyblue1\")) +\n    theme(plot.title = element_text(face = \"bold\", size = 10), \n          axis.title.y = element_text(size = 9), \n          axis.text.x = element_text(size = 8, angle = 45, hjust = 1), \n          legend.title = element_text(face = \"bold\", size = 9), \n          legend.text = element_text(face = \"bold\", size = 8))\n  \n  print(plot)\n}"
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#randomly-picking-reads",
    "href": "posts/2024-12-15-TMM_normalization/index.html#randomly-picking-reads",
    "title": "Trimmed Mean of M-values",
    "section": "Randomly picking reads ü§èüèº",
    "text": "Randomly picking reads ü§èüèº\nThe differences in total expression between samples wouldn‚Äôt represent a major issue if we had the capacity to sequence all molecules present in each sample, just as we have been assuming. But in reality, in RNA-sequencing experiments we have a fixed number of reads per library, meaning not all molecules can be sequenced in each sample but there‚Äôs a sampling of molecules from which reads are generated. Think of it as having the pool of reads for all transcripts expressed in a sample, and having to randomly select a fixed number of them.\n\n\n\n\n\nFor this reason, RNA-seq counts suffer from sampling effects. In the next section we‚Äôll clearly see why this property in RNA-seq data represents an issue in downstrem analysis."
  },
  {
    "objectID": "posts/2024-12-15-TMM_normalization/index.html#hypothetical-scenarios",
    "href": "posts/2024-12-15-TMM_normalization/index.html#hypothetical-scenarios",
    "title": "Trimmed Mean of M-values",
    "section": "Hypothetical scenarios",
    "text": "Hypothetical scenarios\nImagine we have 15 samples across 3 experimental conditions (A, B, and C), each containing all the transcripts expressed from 30 genes with the same length. Suppose all transcripts in each sample are sequenced, without restricting the number of sequenced molecules per library. This fictional scenario would result in sequencing reads for all transcripts per gene, thus serving as estimates of true total expression*.\nThen, think of the following three cases:\n\nCase 1: Highly-expressed genes in one condition:\nOf the 30 genes, 27 have similar expression levels in all three conditions, and 3 are more highly-expressed in condition A than in the other two conditions (genes 5, 6, and 7).\n\n\n\n\n\n\nBelow, we create a matrix of raw read counts from a negative binomial distribution centered in 50, for all 30 genes across the 15 samples. Then, we introduce the 3 highly-expressed genes (counts from 1,000 to 2,000) in condition A only.\n\n\nShow code\nlibrary(ComplexHeatmap)\nlibrary(circlize)\n\n## 15 samples across 3 conditions \nconditions &lt;- rep(c(\"A\", \"B\", \"C\"), c(4, 5, 6))\n\n################################################################\n##                           Case 1:\n################################################################\n\n## Raw counts for 30 genes across the 15 samples as:\n## random numbers following a NB with mean = mu and var = mu + (mu^2/size)\nset.seed(12242024)\nexpr_case1 &lt;- matrix(data = rnbinom(450, mu=50, size=20), nrow = 30)\ncolnames(expr_case1) &lt;- conditions\nrownames(expr_case1) &lt;- paste(\"gene\", 1:30)\n\n## Introduce the 3 highly-expressed genes in condition A \nexpr_case1[c(\"gene 5\", \"gene 6\", \"gene 7\"), 1:4] &lt;- sample(c(1000:2000), replace = T, size = 12)\n\n\n## Heat map\ncol_anno &lt;- HeatmapAnnotation(\n  Condition = anno_block(gp = gpar(fill = c(\"orchid1\", \"palegreen1\", \"deepskyblue1\"), \n                                   col = \"black\"), show_name = T), \n  annotation_name_gp =  gpar(fontsize = 9, fontface = \"bold\"))\n\nHeatmap(expr_case1,\n        name = \"Raw counts\", \n        top_annotation = col_anno, \n        col = colorRamp2(c(1, 10, 100, 2000), \n                         c(\"linen\", \"mistyrose2\", \"rosybrown2\", \"darkred\")),\n        cluster_rows = FALSE,\n        cluster_columns = FALSE,\n        column_split = conditions,\n        column_title = \"Samples\",\n        column_title_gp = gpar(fontsize = 10, fontface = \"bold\"),\n        column_names_side = \"top\",\n        column_names_gp = gpar(fontsize = 9, fontface = \"bold\"),\n        column_names_rot = 0,\n        show_row_names = TRUE,\n        row_names_gp = gpar(fontsize = 8),\n        row_names_side = \"left\",\n        border = TRUE,\n        heatmap_width = unit(12.5, \"cm\"),\n        heatmap_height = unit(12.5, \"cm\")\n)\n\n\n\n\n\n\n\n\n\n\nCase 2: Genes expressed uniquely in one condition:\nIn a separate scenario, imagine that of the 30 genes, half are similarly expressed across the three conditions and half are uniquely expressed in condition A, but at the same level as the other genes. In such way, samples of condition A have twice the number of expressed genes of samples in B and C.\n\n\n\nShow code\n################################################################\n##                           Case 2:\n################################################################\n\n## 15 genes similarly expressed in all samples\nset.seed(12242024)\nexpr_case2 &lt;- matrix(data = rnbinom(225, mu=50, size=20), nrow = 15)\ncolnames(expr_case2) &lt;- conditions\n\n## Add 15 genes expressed in condition A samples only\nexpr_case2 &lt;- rbind(expr_case2, \n                    cbind(matrix(rnbinom(60, mu=50, size=20), nrow = 15), \n                          matrix(0, nrow = 15, ncol = 11))\n              )\n\nrownames(expr_case2) &lt;- paste(\"gene\", 1:30)\n\n## Heat map\nHeatmap(expr_case2,\n        name = \"Raw counts\", \n        top_annotation = col_anno, \n        col = colorRamp2(c(0, 1, 10, 100, 2000), \n                         c(\"gray95\", \"linen\", \"mistyrose2\", \"rosybrown2\", \"darkred\")),\n        cluster_rows = FALSE,\n        cluster_columns = FALSE,\n        column_split = conditions,\n        column_title = \"Samples\",\n        column_title_gp = gpar(fontsize = 10, fontface = \"bold\"),\n        column_names_side = \"top\",\n        column_names_gp = gpar(fontsize = 9, fontface = \"bold\"),\n        column_names_rot = 0,\n        show_row_names = TRUE,\n        row_names_gp = gpar(fontsize = 8),\n        row_names_side = \"left\",\n        border = TRUE,\n        heatmap_width = unit(12.5, \"cm\"),\n        heatmap_height = unit(12.5, \"cm\")\n)\n\n\n\n\n\n\n\n\n\nCase 3: Highly-expressed genes unique to one condition:\nIn the third scenario, of the 30 genes, 27 have similar expression levels in all 3 conditions, and 3 are uniquely expressed in condition A and are more highly-expressed than the rest of genes (genes 28, 29, and 30).\n\n\n\nShow code\n################################################################\n##                           Case 3:\n################################################################\n\n## 27 similarly expressed genes in all samples\nset.seed(12242024)\nexpr_case3 &lt;- matrix(data = rnbinom(405, mu=50, size=20), nrow = 27)\ncolnames(expr_case3) &lt;- conditions\n\n## Add the 3 highly-expressed genes in condition A only\nexpr_case3 &lt;- rbind(expr_case3, \n                    cbind(matrix(sample(c(1000:2000), replace = T, size = 12), nrow = 3), \n                          matrix(0, nrow = 3, ncol = 11))\n              )\nrownames(expr_case3) &lt;- paste(\"gene\", 1:30)\n\n## Heat map\nHeatmap(expr_case3,\n        name = \"Raw counts\", \n        top_annotation = col_anno, \n        col = colorRamp2(c(0, 1, 10, 100, 2000), \n                         c(\"gray95\", \"linen\", \"mistyrose2\", \"rosybrown2\", \"darkred\")),\n        cluster_rows = FALSE,\n        cluster_columns = FALSE,\n        column_split = conditions,\n        column_title = \"Samples\",\n        column_title_gp = gpar(fontsize = 10, fontface = \"bold\"),\n        column_names_side = \"top\",\n        column_names_gp = gpar(fontsize = 9, fontface = \"bold\"),\n        column_names_rot = 0,\n        show_row_names = TRUE,\n        row_names_gp = gpar(fontsize = 8),\n        row_names_side = \"left\",\n        border = TRUE,\n        heatmap_width = unit(12.5, \"cm\"),\n        heatmap_height = unit(12.5, \"cm\")\n)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nCaution\n\n\n\n*The number of reads mapping to a given gene in a sample depends on gene expression (number of gene transcripts), sequencing depth (number of sequenced reads), and gene length: larger genes result in more mapping reads. Thus, read counts are not direct estimations of gene expression. In our examples, however, we are assuming all existing transcripts in a sample are captured and equally sequenced and genes have the same length, so read counts reflect expression."
  },
  {
    "objectID": "posts/2025-08-10-pvals_uniform_distribution/index.html",
    "href": "posts/2025-08-10-pvals_uniform_distribution/index.html",
    "title": "Why are p-values uniformly distributed?",
    "section": "",
    "text": "‚ö†Ô∏è This page is under development."
  },
  {
    "objectID": "posts/2025-08-10-pvals_uniform_distribution/index.html#left-tailed-p-value",
    "href": "posts/2025-08-10-pvals_uniform_distribution/index.html#left-tailed-p-value",
    "title": "Why are p-values uniformly distributed?",
    "section": "Left-tailed p-value",
    "text": "Left-tailed p-value\nTo understand why p-values are uniformly distributed, let‚Äôs start by taking all observations of \\(X\\) that are below the 1st decile, i.e., the bottom 10% of the data. While here I‚Äôm using deciles for simplicity of explanation, the principles presented below generalize to any data percentages.\nFor this purpose, we build a function to annotate each observed value of \\(X\\) with the decile interval they fall into, a second function to plot the density of \\(X\\) highlighting consecutive intervals that each contain 10% of the data, and a third we‚Äôll use later to plot the histogram of p-values of data points in selected decile intervals.\n\n\nShow functions\nlibrary(dplyr)\n\n## Function to annotate decile range of each data point\nannotate_decile_range &lt;- function(decile){\n    \n  q = decile\n  decile_range &lt;- if_else(df$x &lt;= quantile(df$x, q), paste(\"leq\", q), paste(\"g\", q))\n  \n  while(q &gt; 0.1){\n    ## If each observation is between decile q-1 and q\n    decile_range[which(df$x &gt; quantile(df$x, q-0.1) & \n                         df$x &lt;= quantile(df$x, q))] &lt;- paste(\"g\", q-0.1, \", leq\", q)\n    q = q - 0.1\n  }\n  decile_range[which(df$x &lt;= quantile(df$x, 0.1))] &lt;- \"leq 0.1\"\n  \n  df$decile_range &lt;- decile_range\n  \n  return(df)\n}\n  \n\n## Function to plot decile intervals in X density up to q decile\nplot_density_decile &lt;- function(decile){\n  \n  df &lt;- annotate_decile_range(decile)\n  \n  ## Colors and alphas for decile ranges\n  range_colors = c(colorRampPalette(c(\"mistyrose\", \"lightpink\", \"palevioletred\", \n                                    \"palevioletred4\"))(10), \"gray90\")\n  range_alphas = c(rep(1, 10), 0.2)\n  names(range_colors) &lt;- names(range_alphas) &lt;- c(\"leq 0.1\", \n                                   paste(\"g\", seq(from = 0.1, to = 0.9, by = 0.1), \",\", \"leq\", \n                                         seq(from = 0.1, to = 0.9, by = 0.1) + 0.1), \n                                   paste(\"g\", decile))\n  \n  vlines &lt;- vector()\n  for(q in seq(from = 0.1, to = decile, by = 0.1)){\n    \n    ## For vertical lines in each decile \n    x = quantile(df$x, q)\n    xend = quantile(df$x, q)\n    y = 0\n    yend = df[which.min(abs(df$x - x)), \"y\"]\n    \n    ## For annotating \"10%\" above each decile range\n    prior_x = quantile(df$x, q-0.1)\n    prior_yend = df[which.min(abs(df$x - prior_x)), \"y\"]\n    middle_x = prior_x + (x - prior_x)/2\n    middle_y = prior_yend + (yend - prior_yend)/2\n   \n    if(q == 0.1){\n      lab_x_pos = middle_x\n      lab_y_pos = middle_y - 0.04\n    }\n    else if(q == 1){\n      lab_x_pos = middle_x\n      lab_y_pos = middle_y - 0.03\n    }\n    else if(q == 0.5){\n      lab_x_pos = middle_x - 0.05\n      lab_y_pos = middle_y + 0.014\n    }\n    else if(q == 0.6){\n      lab_x_pos = middle_x + 0.12\n      lab_y_pos = middle_y + 0.014\n    }\n    else{\n      lab_x_pos = middle_x + (sign(x)*0.17)\n      diff_y = abs((yend - prior_yend)/2)\n      lab_y_pos = middle_y + (diff_y*0.33)\n    }\n    \n    vlines &lt;- rbind(vlines, c(q, x, xend, y, yend, lab_x_pos, lab_y_pos))\n  }\n    \n  vlines &lt;- as.data.frame(vlines)\n  colnames(vlines) &lt;- c(\"decile\", \"x\", \"xend\", \"y\", \"yend\", \"lab_x_pos\", \"lab_y_pos\")\n  \n  \n  ggplot(data = df, aes(x = x, ymin = 0, ymax = y, \n                        fill = decile_range,\n                        alpha = decile_range)) +\n  geom_ribbon(color = \"black\", linewidth = 0.35) +\n  theme_classic() +\n  scale_fill_manual(values = range_colors) +\n  scale_alpha_manual(values = range_alphas) +\n  labs(x = latex2exp::TeX(\"$X$\"), \n       y = \"Density\") +\n  geom_segment(data = vlines, inherit.aes = F,\n               aes(x = x + 0.005, \n                   xend = xend + 0.005,\n                   y = y, yend = yend), \n               linewidth = 0.35, show.legend = F) +\n  geom_text(data = vlines, inherit.aes = F,\n                aes(x = lab_x_pos, y = lab_y_pos), label =\"10%\", \n            size = 2.4, show.legend = F) +\n  guides(fill = \"none\", alpha = \"none\") +\n  coord_cartesian(ylim = c(0, max(df$y)+0.02), expand = F) +\n  theme(axis.text = element_text(size = 9),\n        legend.text = element_text(size = 7),\n        legend.title = element_text(size =8),\n        legend.key.height = unit(0.5, \"cm\"), \n        legend.key.width = unit(0.5, \"cm\"),\n        axis.title.x = element_text(size = 10),\n        axis.title.y = element_text(size = 10))\n}\n\n\n## Function to plot pval histogram up to decile q\nplot_pval_hist &lt;- function(decile, tail){\n  \n  if(tail == \"left\"){\n    tail_pvals &lt;- \"left_tailed_pval\"\n  } else if(tail == \"right\"){\n    tail_pvals &lt;- \"right_tailed_pval\"\n  } else{\n    tail_pvals &lt;- \"two_tailed_pval\"\n  }\n  \n  \n  ## Colors and alphas for decile ranges\n  range_colors = colorRampPalette(c(\"mistyrose\", \"lightpink\", \"palevioletred\", \n                                    \"palevioletred4\"))(10)\n  names(range_colors) &lt;- c(\"leq 0.1\", \n                                   paste(\"g\", seq(from = 0.1, to = 0.9, by = 0.1), \",\", \"leq\", \n                                              seq(from = 0.1, to = 0.9, by = 0.1) + 0.1))\n\n  decile_ranges_labs &lt;- c(\"bottom 10%\", \"between 10-20%\", \"between 20-30%\", \"between 30-40%\",\n                          \"between 40-50%\", \"between 50-60%\", \"between 60-70%\",\n                          \"between 70-80%\",\"between 80-90%\", \"top 10%\")\n  names(decile_ranges_labs) &lt;- names(range_colors)\n\n  df &lt;- annotate_decile_range(decile)\n  decile_ranges &lt;- setdiff(unique(df$decile_range), paste(\"g\", decile))\n\n  data = subset(df, decile_range %in% decile_ranges)\n  data$decile_range &lt;- factor(data$decile_range, levels = names(decile_ranges_labs))\n\n  ggplot(data, aes(x = get(tail_pvals), fill = decile_range)) +\n  geom_histogram(color=\"black\", bins = 10, binwidth = 0.3, linewidth = 0.4,\n                 breaks = seq(from = 0, to = 1, by = 0.1))  +\n  theme_classic() +\n  scale_fill_manual(values = range_colors, labels = decile_ranges_labs[decile_ranges]) +\n  coord_cartesian(xlim = c(-0.02, 1.02), ylim = c(0, 1050), expand = F) +\n  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),\n                     labels = seq(from = 0, to = 1, by = 0.1)) +\n    labs(x = \"p-value\", y = \"Count\", fill = \"Decile range\") +\n    theme(axis.text = element_text(size = 9),\n          legend.text = element_text(size = 7),\n          legend.title = element_text(size =8),\n          legend.key.height = unit(0.5, \"cm\"),\n          legend.key.width = unit(0.5, \"cm\"),\n          axis.title.x = element_text(size = 10),\n          axis.title.y = element_text(size = 10))\n\n}\n\n\n\nplot_density_decile(0.1)\n\n\n\n\n\n\n\n\nRevisiting the definition of the left-tailed p-value for any observed \\(x\\): \\(p(x) = F_X(x) = P(X \\leq x)\\), the probabilites of \\(X\\) being smaller or equal to each of the data points within this bottom 10%, are \\(\\leq\\) 0.1. Let‚Äôs check this by computing the left-tailed p-value for all observations and plot the histogram for those within the 1st decile.\n\n## Left-tailed p-vals\ndf$left_tailed_pval &lt;- sapply(df$x, function(x){table(df$x &lt;= x)[\"TRUE\"]/10000})\n\n## Hist of pvals for bottom 10% data points\nplot_pval_hist(0.1, \"left\")\n\n\n\n\n\n\n\n\nNext, we include an additional 10% of the data (the observations between the 1st and 2nd deciles) and examine their p-values.\n\nlibrary(cowplot)\n\np1 &lt;- plot_density_decile(0.2)\np2 &lt;- plot_pval_hist(0.2, \"left\")\n\nplot_grid(p1, p2, align = \"h\")\n\n\n\n\n\n\n\n\nIntuitively, because every time we take the same % of the data between the \\(q = {1,2,3, ..., 10}\\)th and \\(q-1\\)th deciles, and because their p-values lie between \\(q\\)/10 and (\\(q-1\\))/10, bars have the same height in the histogram.\nYou see it now, isn‚Äôt? If not, let‚Äôs try adding more‚Äî30%, 40%, 50%‚Ä¶ up to the full dataset.\n\nplot_grid(plot_density_decile(0.3), plot_pval_hist(0.3, \"left\"), \n          plot_density_decile(0.4), plot_pval_hist(0.4, \"left\"), \n          plot_density_decile(0.5), plot_pval_hist(0.5, \"left\"), \n          plot_density_decile(0.6), plot_pval_hist(0.6, \"left\"), \n          plot_density_decile(1), plot_pval_hist(1, \"left\"), align = \"vh\", ncol = 2, rel_widths = c(1, 0.6))\n\n\n\n\n\n\n\n\nThis can be formally demonstrated. The probability integral transform theorem states that for \\(X\\), a continuous random variable, the random variable for its cumulative distribution function \\(Y = F_X(x) = P(X \\leq x)\\), which returns its p-values, has a uniform distribution on the interval .\nProof: consider the cumulative distribution function for \\(Y\\): \\(F_Y(y) = P(Y \\leq y)\\). Substituting, \\(F_Y(y) = P(F_X(x) \\leq y)\\). What‚Äôs key here is that the probability of getting p-values below or equal to \\(y\\) (i.e.¬†\\(P(Y\\leq y)\\), is equivalent to the probability of getting \\(X\\) values smaller or equal to the quantile for that \\(y\\) proportion. So \\(P(F_X(x) \\leq y) = P(X \\leq F{-1}_X(y))\\), probability which, by construction equals to \\(y\\). Thus \\(F_Y(y)=P(Y \\leq y) = y\\) and is thus uniformly distributed."
  },
  {
    "objectID": "posts/2025-08-10-pvals_uniform_distribution/index.html#right-tailed-p-values",
    "href": "posts/2025-08-10-pvals_uniform_distribution/index.html#right-tailed-p-values",
    "title": "Why are p-values uniformly distributed?",
    "section": "Right-tailed p-values",
    "text": "Right-tailed p-values\nFor right-tailed p-values the pattern is mirrored: the bottom 10% of test statistics have p-values between 0.9 to 1 so their p-values\nThe second top 10% between 0.8 and 0.9, and so on ‚Ä¶ Their\n\n## Right-tailed p-vals\n# df$right_tailed_pval &lt;- sapply(df$t, function(t){table(df$t &gt; t)[\"TRUE\"]/10000})\n# df$right_tailed_pval &lt;- replace(df$right_tailed_pval, which(is.na(df$right_tailed_pval)), 0)\n# \n# plot_pval_hist(0.1, \"right\")\n\n\nMathematical demonstration\nProof: we define \\(Y_c = P(T &gt; t) = 1 - Y\\), with \\(Y = P(T \\le t)\\). The CDF of \\(Y_c\\) is given by \\(P(Y_c\\le y) = 1 - P(Y_c &gt; y)\\). The key here is to note that the those right-handed p-values greater than \\(y\\) correspond to the bottom \\(1-y\\) proportion of the data so that \\(P(Y_c &gt; y) = P(X \\leq F^{-1}_X(1-y))\\), which by definition, equals \\(1-y\\) (see example below). Therefore \\(P(Y_c &gt;y) = 1-y\\) and \\(P(Y_c\\leq y) = 1 - (1 - y) = y\\), and both, \\(Y\\) and its complement \\(Y_c\\), follow an uniform distribution.\n\n## Pr(X ‚â§ quantile for 1 - 0.7)\n# p1 &lt;- plot_density_decile(0.3)\n# ## Pr(Yc &gt; 0.7)\n# p2 &lt;- plot_pval_hist(0.3, \"right\")\n# \n# plot_grid(p2, p1, align = \"h\")"
  },
  {
    "objectID": "posts/2025-04-11-FDR_and_qvalue/index.html",
    "href": "posts/2025-04-11-FDR_and_qvalue/index.html",
    "title": "Understanding False Discovery Rate and q-values",
    "section": "",
    "text": "‚ö†Ô∏è This page is under development."
  },
  {
    "objectID": "posts/2025-08-10-pvals_uniform_distribution/index.html#proof",
    "href": "posts/2025-08-10-pvals_uniform_distribution/index.html#proof",
    "title": "Why are p-values uniformly distributed?",
    "section": "‚ÄúProof‚Äù",
    "text": "‚ÄúProof‚Äù\nLet a random variable,¬†, be defined by¬†¬†where¬†¬†is another random variable. Then,"
  },
  {
    "objectID": "posts/2025-08-10-pvals_uniform_distribution/index.html#what-about-right-tailed-p-values",
    "href": "posts/2025-08-10-pvals_uniform_distribution/index.html#what-about-right-tailed-p-values",
    "title": "Why are p-values uniformly distributed?",
    "section": "What about right-tailed p-values?",
    "text": "What about right-tailed p-values?\nSimilarly, for p-values on the right hand of the distribution, the behavior is exactly the opposite: the top 10% pf the data points have p-values between 0.9 to 1, the second top 10% have p-values from 0.8 to 0.9, and so on ‚Ä¶\n\n## Right-tailed p-vals\ndf$right_tailed_pval &lt;- sapply(df$x, function(x){table(df$x &gt; x)[\"TRUE\"]/10000})\ndf$right_tailed_pval &lt;- replace(df$right_tailed_pval, which(is.na(df$right_tailed_pval)), 0)\n\n## Hist of pvals for bottom 10% data points\nplot_pval_hist(1, \"right\")\n\n\n\n\n\n\n\n\nAnd for two-tailed p-values\n\n## Right-tailed p-vals\ndf$two_tailed_pval &lt;- apply(df, 1, function(x){2*as.double(min(x[\"left_tailed_pval\"], x[\"right_tailed_pval\"]))})\n\n## Hist of pvals for bottom 10% data points\nplot_pval_hist(1, \"both\")\n\n\n\n\n\n\n\nplot_pval_hist(0.1, \"both\")\n\n\n\n\n\n\n\nplot_pval_hist(0.2, \"both\")\n\n\n\n\n\n\n\nplot_pval_hist(0.5, \"both\")\n\n\n\n\n\n\n\nplot_pval_hist(0.6, \"both\")\n\n\n\n\n\n\n\nplot_pval_hist(1, \"both\")\n\n\n\n\n\n\n\n\n\nShow for right tail pvals\nShow for two sided pvals\nRelate to theorem and CDF and PDF: https://matthewfeickert.github.io/Statistics-Notes/notebooks/Introductory/probability-integral-transform.html\n\nIdeas:\n\nWhen p-values¬†are¬†uniformly distributed\n\nUnder the null hypothesis¬†is¬†true\nThe test statistic‚Äôs reference distribution is correct¬†(e.g., you‚Äôre actually using the right t-distribution, œá¬≤ distribution, etc.)\nNo p-hacking¬†or data snooping has been done\nContinuous¬†test statistic (ties complicate things)\n\nIn that ideal case,\nP(p‚â§Œ±)=Œ±P(p‚â§Œ±)=Œ±\nfor all¬†Œ±‚àà[0,1]Œ±‚àà[0,1],\nmeaning the p-value follows a Uniform(0,1) distribution.\n\n\n\nWhen they are¬†not¬†uniformly distributed\n\nNull hypothesis is false¬†‚Üí p-values are¬†stochastically smaller¬†(skewed toward 0)\nModel assumptions are violated¬†(wrong reference distribution, heteroscedasticity, etc.) ‚Üí distribution can be distorted in unpredictable ways\nDiscrete test statistics¬†(e.g., Fisher‚Äôs exact test) ‚Üí distribution is ‚Äústepped‚Äù and not perfectly uniform\nMultiple testing without correction¬†‚Üí aggregated p-values no longer follow a simple uniform distribution\nSelection bias / p-hacking¬†‚Üí distribution can become heavily biased toward small values\n\n\n‚úÖ¬†Bottom line:\nP-values are¬†theoretically¬†Uniform(0,1)¬†only under the null and correct modeling assumptions.\nThe reference distribution does matter ‚Äî if it‚Äôs wrong, the uniformity breaks."
  },
  {
    "objectID": "posts/2025-08-10-pvals_uniform_distribution/index.html#left-tailed-p-values",
    "href": "posts/2025-08-10-pvals_uniform_distribution/index.html#left-tailed-p-values",
    "title": "Why are p-values uniformly distributed?",
    "section": "Left-tailed p-values",
    "text": "Left-tailed p-values\nTo visualize why p-values are uniformly distributed, let‚Äôs consider all test statistics in the null distribution that fall below or at the 1st decile (\\(t_{_{10\\%}}\\))‚Äîthat is, the bottom 10%.\n\n\n\n\n\n\nNote\n\n\n\nAlthough deciles are used here for simplicity, the same reasoning applies to any proportion of the data.\n\n\nFor this purpose, we build three functions. The first annotates each test statistic \\(t\\) with the decile interval it falls into in the simulated null distribution; the second plots the density of \\(T\\) showing selected decile intervals, and the third plots the histogram of p-values for all test statistics contained in such intervals.\n\n\nShow functions\nlibrary(grid)\n\n## 1. Function to annotate decile interval for each test statistic t\nannotate_decile_range &lt;- function(decile){\n    \n  q = decile\n  ## First annotate if each t is &lt;= decile q\n  decile_range &lt;- if_else(df$t &lt;= quantile(df$t, q), paste(\"leq\", q), paste(\"g\", q))\n  \n  while(q &gt; 0.1){\n    ## Then annotate if each t is between decile q-1 and q\n    decile_range[which(df$t &gt; quantile(df$t, q-0.1) & \n                         df$t &lt;= quantile(df$t, q))] &lt;- paste(\"g\", q-0.1, \", leq\", q)\n    q = q - 0.1\n  }\n  decile_range[which(df$t &lt;= quantile(df$t, 0.1))] &lt;- \"leq 0.1\"\n  \n  df$decile_range &lt;- decile_range\n  \n  return(df)\n}\n  \n\n## 2. Function to color decile intervals in T density up to decile q\nplot_density_decile &lt;- function(decile){\n  \n  df &lt;- annotate_decile_range(decile)\n  \n  ## Colors and alphas for decile ranges\n  range_colors = c(colorRampPalette(c(\"honeydew1\", \"azure2\", \"thistle2\",\"plum\",\n                                    \"sienna2\"))(10), \"gray90\")\n  range_alphas = c(rep(1, 10), 0.2)\n  names(range_colors) &lt;- names(range_alphas) &lt;- c(\"leq 0.1\", \n                                   paste(\"g\", seq(from = 0.1, to = 0.9, by = 0.1), \",\", \"leq\", \n                                         seq(from = 0.1, to = 0.9, by = 0.1) + 0.1), \n                                   paste(\"g\", decile))\n  \n  vlines &lt;- vector()\n  for(q in seq(from = 0.1, to = decile, by = 0.1)){\n    \n    ## For vertical lines in each decile \n    x = quantile(df$t, q)\n    xend = quantile(df$t, q)\n    y = 0\n    yend = df[which.min(abs(df$t - x)), \"y\"]\n    \n    ## For annotating \"10%\" above each decile interval\n    prior_x = quantile(df$t, q-0.1)\n    prior_yend = df[which.min(abs(df$t - prior_x)), \"y\"]\n    middle_x = prior_x + (x - prior_x)/2\n    middle_y = prior_yend + (yend - prior_yend)/2\n   \n    if(q == 0.1){\n      lab_x_pos = middle_x\n      lab_y_pos = middle_y - 0.04\n    }\n    else if(q == 1){\n      lab_x_pos = middle_x\n      lab_y_pos = middle_y - 0.03\n    }\n    else if(q == 0.5){\n      lab_x_pos = middle_x - 0.05\n      lab_y_pos = middle_y + 0.014\n    }\n    else if(q == 0.6){\n      lab_x_pos = middle_x + 0.12\n      lab_y_pos = middle_y + 0.014\n    }\n    else{\n      lab_x_pos = middle_x + (sign(x)*0.17)\n      diff_y = abs((yend - prior_yend)/2)\n      lab_y_pos = middle_y + (diff_y*0.33)\n    }\n    \n    vlines &lt;- rbind(vlines, c(q, x, xend, y, yend, lab_x_pos, lab_y_pos))\n  }\n    \n  vlines &lt;- as.data.frame(vlines)\n  colnames(vlines) &lt;- c(\"decile\", \"x\", \"xend\", \"y\", \"yend\", \"lab_x_pos\", \"lab_y_pos\")\n  \n  \n  plot &lt;- ggplot(data = df, aes(x = t, ymin = 0, ymax = y, \n                        fill = decile_range,\n                        alpha = decile_range)) +\n  geom_ribbon(color = \"black\", linewidth = 0.35) +\n  theme_classic() +\n  scale_fill_manual(values = range_colors) +\n  scale_alpha_manual(values = range_alphas) +\n  labs(x = \"T\", \n       y = \"Density\") +\n  geom_segment(data = vlines, inherit.aes = F,\n               aes(x = x + 0.005, \n                   xend = xend + 0.005,\n                   y = y, yend = yend), \n               linewidth = 0.35, show.legend = F) +\n  geom_text(data = vlines, inherit.aes = F,\n                aes(x = lab_x_pos, y = lab_y_pos), label =\"10%\", \n            size = 2.4, show.legend = F) +\n  guides(fill = \"none\", alpha = \"none\") +\n  coord_cartesian(ylim = c(0, max(df$y)+0.02), expand = F) +\n  theme(axis.text = element_text(size = 9),\n        legend.text = element_text(size = 7),\n        legend.title = element_text(size =8),\n        legend.key.height = unit(0.5, \"cm\"), \n        legend.key.width = unit(0.5, \"cm\"),\n        axis.title.x = element_text(size = 10),\n        axis.title.y = element_text(size = 10))\n  \n  ## To add labels for 1st and 2nd deciles\n  if(decile == 0.1){\n    plot &lt;- plot + geom_text(aes(x = vlines[1,\"x\"], y = 0.015,\n                                 label =  expression(t[\"10%\"])), \n                             inherit.aes = F, parse = T, size = 3)\n  }\n  else if(decile == 0.2){\n    plot &lt;- plot + geom_text(aes(x = vlines[1,\"x\"]-0.07, y = 0.015,\n                                 label =  expression(t[\"10%\"])), \n                             inherit.aes = F, parse = T, size = 2.7) + \n                   geom_text(aes(x = vlines[2,\"x\"]+0.07, y = 0.015,\n                                 label =  expression(t[\"20%\"])), \n                             inherit.aes = F, parse = T, size = 2.7)\n  }\n  \n  return(plot)\n}\n\n\n## 3. Function to plot pval histogram up to decile q\nplot_pval_hist &lt;- function(decile, tail){\n  \n  if(tail == \"left\"){\n    tail_pvals &lt;- \"left_tailed_pval\"\n  } else if(tail == \"right\"){\n    tail_pvals &lt;- \"right_tailed_pval\"\n  } else{\n    tail_pvals &lt;- \"two_tailed_pval\"\n  }\n  \n  ## Colors and alphas for decile ranges\n  range_colors = colorRampPalette(c(\"honeydew1\", \"azure2\",\"thistle2\",\"plum\",\n                                    \"sienna2\"))(10)\n  names(range_colors) &lt;- c(\"leq 0.1\", \n                                   paste(\"g\", seq(from = 0.1, to = 0.9, by = 0.1), \",\", \"leq\", \n                                              seq(from = 0.1, to = 0.9, by = 0.1) + 0.1))\n\n  decile_ranges_labs &lt;- c(\"bottom 10%\", \"between 10-20%\", \"between 20-30%\", \"between 30-40%\",\n                          \"between 40-50%\", \"between 50-60%\", \"between 60-70%\",\n                          \"between 70-80%\",\"between 80-90%\", \"top 10%\")\n  names(decile_ranges_labs) &lt;- names(range_colors)\n\n  df &lt;- annotate_decile_range(decile)\n  decile_ranges &lt;- setdiff(unique(df$decile_range), paste(\"g\", decile))\n\n  data = subset(df, decile_range %in% decile_ranges)\n  data$decile_range &lt;- factor(data$decile_range, levels = names(decile_ranges_labs))\n  \n  if(tail == \"both\"){\n    data$decile_range &lt;- factor(data$decile_range, levels = rev(names(decile_ranges_labs)))\n  }\n\n  ## Histogram\n  ggplot(data, aes(x = get(tail_pvals), fill = decile_range)) +\n  geom_histogram(color=\"black\", bins = 10, binwidth = 0.3, linewidth = 0.4,\n                 breaks = seq(from = 0, to = 1, by = 0.1))  +\n  theme_classic() +\n  scale_fill_manual(values = range_colors, labels = decile_ranges_labs[decile_ranges]) +\n  coord_cartesian(xlim = c(-0.02, 1.02), ylim = c(0, 1050), expand = F) +\n  scale_x_continuous(breaks = seq(from = 0, to = 1, by = 0.1),\n                     labels = seq(from = 0, to = 1, by = 0.1)) +\n    labs(x = \"p-value\", y = \"Count\", fill = \"Decile interval\") +\n    theme(axis.text = element_text(size = 9),\n          legend.text = element_text(size = 7),\n          legend.title = element_text(size =8),\n          legend.key.height = unit(0.5, \"cm\"),\n          legend.key.width = unit(0.5, \"cm\"),\n          axis.title.x = element_text(size = 10),\n          axis.title.y = element_text(size = 10))\n\n}\n\n\nLet‚Äôs look at the bottom 10% of test statistics under the null distribution.\n\nplot_density_decile(0.1)\n\n\n\n\n\n\n\n\nNote that because these test statistics represent 10% of the data, the probability that a random draw from the null distribution will be any of these values is 10% , i.e.¬†\\(P(T \\leq t_{_{10\\%}}) = p_{_{left}}(t_{_{10\\%}})  = 0.1\\), and this is true for any other quantile. Therefore, all statistics \\(t\\) in the first decile interval have probabilities smaller or equal to 0.1: \\(p_{_{left}}(t) = P(T \\le t) \\le 0.1 \\ \\ \\forall t \\le t_{_{10\\%}}\\).\nLet‚Äôs confirm this by computing the left-tailed p-value for all test statistics in the null distribution and displaying the histogram of p-values for those within the 1st decile interval.\n\n## Left-tailed p-vals\ndf$left_tailed_pval &lt;- sapply(df$t, function(t){table(df$t &lt;= t)[\"TRUE\"]/10000})\n\n## Hist of pvals for bottom 10% \nplot_pval_hist(0.1, \"left\")\n\n\n\n\n\n\n\n\nNow, for the subsequent 10% of test statistics‚Äîthose between deciles \\(t_{_{10\\%}}\\) and \\(t_{_{20\\%}}\\), their p-values lie in (0.1, 02]: \\(0.1 &lt; p_{_{left}}(t) = P(T \\le t) \\le 0.2 \\ \\ \\forall \\ \\ t_{_{10\\%}} &lt; t \\le t_{_{20\\%}}\\).\n\nlibrary(cowplot)\n\np1 &lt;- plot_density_decile(0.2)\np2 &lt;- plot_pval_hist(0.2, \"left\")\n\nplot_grid(p1, p2, align = \"h\")\n\n\n\n\n\n\n\n\nBecause every time we take the same percentage of test statistics lying between the \\(q\\)th and \\((q-1)\\)th deciles for \\(q = \\{1,2,3, ..., 10\\}\\), and because their p-values are contained between \\(\\frac{q-1}{10}\\) and \\(\\frac{q}{10}\\), bars have the same height in the histogram.\nSee it now, isn‚Äôt? If not, let‚Äôs try adding more data‚Äî30%, 40%, 50% ‚Ä¶ up to the whole distribution.\n\nplot_grid(plot_density_decile(0.3), plot_pval_hist(0.3, \"left\"), \n          plot_density_decile(0.4), plot_pval_hist(0.4, \"left\"), \n          plot_density_decile(1), plot_pval_hist(1, \"left\"), align = \"vh\", ncol = 2, rel_widths = c(1, 0.8))\n\n\n\n\n\n\n\n\n\nMathematical demonstration\nThese observations can be formally demonstrated. The probability integral transform theorem states that for \\(T\\), a continuous random variable, the random variable for its cumulative distribution function \\(Y = F_T(t) = P(T \\le t)\\), (which returns its left-tailed p-values) has a uniform distribution on the interval \\([0,1]\\).\nProof: consider the cumulative distribution function of \\(Y\\), \\(F_Y(y) = P(Y \\leq y)\\). The key is to note that the probability of getting p-values below or equal to \\(y\\) is equivalent to the probability of getting \\(T\\) statistics below or equal to corresponding quantile for \\(y\\) (see example in the code below).\nThat is, \\(P(Y \\le y) = P(T \\le F^{-1}_T(y))\\), which, by definition, is exactly \\(y\\). Thus, \\(F_Y(y)=P(Y \\le y) = y\\) and \\(Y\\) is uniformly distributed.\n\n## Pr(Y ‚â§ 0.456)\npr_Y = sum(df$left_tailed_pval &lt;= 0.456) / length(df$left_tailed_pval) \n## Pr(X ‚â§ quantile for 0.456)\npr_X = sum(df$x &lt;= quantile(df$x, 0.456)) / length(df$x) \npr_Y == pr_X\n\n[1] NA"
  },
  {
    "objectID": "posts/2025-08-10-pvals_uniform_distribution/index.html#two-tailed-p-values",
    "href": "posts/2025-08-10-pvals_uniform_distribution/index.html#two-tailed-p-values",
    "title": "Why are p-values uniformly distributed?",
    "section": "Two-tailed p-values",
    "text": "Two-tailed p-values\nFor data points within intervals of deciles \\(q ‚àà \\{1,2,3,4,5\\}\\), their two-tailed p-values lie between \\(\\frac{q-1}{10}\\times 2\\) and \\(\\frac{q}{10}\\times 2\\), whereas for those above the 5th decile, p-values lie between \\((1-\\frac{q-1}{10})\\times 2\\) and \\((1-\\frac{q}{10})\\times 2\\).\n\n## Right-tailed p-vals\n# df$two_tailed_pval &lt;- apply(df, 1, function(x){2*as.double(min(x[\"left_tailed_pval\"], x[\"right_tailed_pval\"]))})\n# \n# ## Hist of pvals for bottom 10% data points\n# p1 &lt;- plot_pval_hist(0.1, \"both\") +  guides(fill = guide_legend(reverse = TRUE))\n# p2 &lt;- plot_pval_hist(0.2, \"both\") +  guides(fill = guide_legend(reverse = TRUE))\n# p3 &lt;- plot_pval_hist(0.6, \"both\") +  guides(fill = guide_legend(reverse = TRUE))\n# p4 &lt;- plot_pval_hist(1, \"both\") +  guides(fill = guide_legend(reverse = TRUE))\n# \n# plot_grid(p1, p2, p3, p4, align = \"h\", ncol = 1)\n\n\nMathematical demonstration\nProof: let \\(Y_l\\) and \\(Y_r\\) be the random variables for two-tailed p-values for observations of \\(X\\) below and above the 5th decile, respectively (bottom and top half of previous histogram, respectively). Let \\(Y_t\\) be the random variable for two-tailed p-values across all observations (the complete histogram). The CDF of \\(Y_t\\) is \\(P(Y_t \\leq y) = \\frac{P(Y_l \\leq y)}{2} + \\frac{P(Y_r \\leq y)}{2} = P(Y \\leq \\frac{y}{2}) + P(Y_c \\leq \\frac{y}{2})\\). Because \\(Y\\) and \\(Y_c\\) are uniformly distributed, the latter equals to \\(\\frac{y}{2} + \\frac{y}{2}\\) so \\(P(Y_t \\leq y) = y\\) and is thus also uniformly distributed.\n\nRelate to theorem and CDF and PDF: https://matthewfeickert.github.io/Statistics-Notes/notebooks/Introductory/probability-integral-transform.html\n\nIdeas:\n\n\nWhen p-values¬†are¬†uniformly distributed\n\nUnder the null hypothesis¬†is¬†true\nThe test statistic‚Äôs reference distribution is correct¬†(e.g., you‚Äôre actually using the right t-distribution, œá¬≤ distribution, etc.)\nNo p-hacking¬†or data snooping has been done\nContinuous¬†test statistic (ties complicate things)\n\nIn that ideal case,\nP(p‚â§Œ±)=Œ±\nfor all¬†Œ±‚àà[0,1]Œ±‚àà[0,1],\nmeaning the p-value follows a Uniform(0,1) distribution.\n\n\n\nWhen they are¬†not¬†uniformly distributed\n\nNull hypothesis is false¬†‚Üí p-values are¬†stochastically smaller¬†(skewed toward 0)\nModel assumptions are violated¬†(wrong reference distribution, heteroscedasticity, etc.) ‚Üí distribution can be distorted in unpredictable ways\nDiscrete test statistics¬†(e.g., Fisher‚Äôs exact test) ‚Üí distribution is ‚Äústepped‚Äù and not perfectly uniform\nMultiple testing without correction¬†‚Üí aggregated p-values no longer follow a simple uniform distribution\nSelection bias / p-hacking¬†‚Üí distribution can become heavily biased toward small values\n\n\n‚úÖ¬†Bottom line:\nP-values are¬†theoretically¬†Uniform(0,1)¬†only under the null and correct modeling assumptions.\nThe reference distribution does matter ‚Äî if it‚Äôs wrong, the uniformity breaks."
  },
  {
    "objectID": "posts/2025-04-11-FDR_and_qvalue/index.html#notes",
    "href": "posts/2025-04-11-FDR_and_qvalue/index.html#notes",
    "title": "Understanding False Discovery Rate and q-values",
    "section": "Notes",
    "text": "Notes\n\nDefine pval and how it controls for FPR\nDefine qval and how it controls for FDR\nP val is V/m0 because its the prop of false positives under the Ho, i.e.¬†among null tests! Not among true alternative tests.\nThe pval not the qval is not the probability of being FP.\nComparison of pvals vs qvalues: less signif ones but less FPs when cutoff at qval\nExplain how the the qvalue is computed from the pvalue and its interpretation from R code, is it equivalent to BH method?"
  },
  {
    "objectID": "posts/2025-04-11-FDR_and_qvalue/index.html#sources",
    "href": "posts/2025-04-11-FDR_and_qvalue/index.html#sources",
    "title": "Understanding False Discovery Rate and q-values",
    "section": "Sources",
    "text": "Sources\n\nStorey paper\nqvalue documentation\np.adjust BH methd, how are pvals adjusted? is it the same as qith qvalue?"
  },
  {
    "objectID": "posts/2025-04-11-FDR_and_qvalue/index.html#code",
    "href": "posts/2025-04-11-FDR_and_qvalue/index.html#code",
    "title": "Understanding False Discovery Rate and q-values",
    "section": "Code",
    "text": "Code\nLet‚Äôs generate a list of p-values from the standard normal distribution\n\n# p &lt;- pnorm(c(rnorm(20), rnorm(5, mean = 5)), lower.tail = F)\n# \n# ## Number of tests\n# m &lt;- length(p)\n# \n# ## Index of test i (= number of tests declared significant i.e. with p&lt;=pi)\n# i &lt;- m:1\n# o &lt;- order(p, decreasing = TRUE)\n# ro &lt;- order(o)\n# \n#  qvals &lt;- pi0s$pi0 * pmin(1, cummin(p[o] * m /i ))[ro]"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Daianna Gonzalez-Padilla",
    "section": "About me",
    "text": "About me\n\nHey! Daianna here. I completed my Bachelor‚Äôs degree in Genomic Sciences at the National Autonomous University of Mexico (LCG-UNAM) in 2024. I am currently a researcher in the group of Dr.¬†Stephen Burgess at the MRC Biostatistics Unit, University of Cambridge. My research applies causal inference methods to identify disease risk factors and potential drug targets that are relevant to specific population subgroups, with the goal of advancing prevention in at-risk groups and leading to the development of more effective, targeted treatments.\nAlong my academic journey, I‚Äôve acquired solid foundations in statistics and bioinformatics that have allowed me to explore a broad range of scientific questions. My experiences as a researcher, student, and instructor, have shaped\nHowever, my scientific aspirations go beyond the implementation of\nA goal of mine is to contribute to conducting rigurous research by disseminating knowledge and training students and life scientists in data science.\nwant to exploit to teach others in a more impactfult way. I want to share with the scientific community. particularly with other students like me that may not have the same opportunities or academic background but also want to analyze datasets to answer biologically-relevant questions."
  },
  {
    "objectID": "index.html#motivation-for-this-blog",
    "href": "index.html#motivation-for-this-blog",
    "title": "Daianna Gonzalez-Padilla",
    "section": "Motivation for this blog",
    "text": "Motivation for this blog\n\n\n\n\n\n\nThrough conducting scientific research, collaborating with peers, and assisting in bioinformatics courses, I have observed two common problems when analyzing data:\n\nIn these interconnected times, with praiseworthy collaborative efforts such as the Bioconductor project we can easily develop, share, and use other people‚Äôs code, data, methods, and even complete packages for our own analyses. That represents an incredible opportunity for all of us to leverage, contribute, and improve popular and new-emerging computational tools for the reproducible analysis of biological data, no doubts! However, for students and novice researchers, and people coming from areas other than biostatistics, computational biology, or bioinformatics, some analyses may represent obscure-if not completely unknown‚Äìterritories. People developing these algorithms often assume they have a specialized audience and tend to trivialize underlying statistical concepts and methods when describing their computational functions and packages, not to mention the poor or even missing documentation and support some of the authors offer (with notable exceptions such as limma and variancePartition, among others).¬†\nSecond, nowadays it is incredibly simple to run a complete pipeline with a single function. That‚Äôs efficient and increases productivity but it also has diluted the needed understanding behind their use. I have found many people, including myself, deludedly thinking we master an analysis only because we have run software programs without errors and have received outputs. We may dominate the practice but that doesn‚Äôt imply nor guarantee we understand the theory.¬†\n\n\nIt seems to me we are a generation of trained students that know how to run an analysis and obtain results, but don‚Äôt understand the analyses themselves; in some occasions, not even the reasons why we execute them. But this is not limited to undergrad or master students: you would be surprised by the number of PhD students, postdocs, and researchers that relate to this!\n\n‚ùóÔ∏è‚ùóÔ∏è‚ùóÔ∏è More alarming than the aforementioned I‚Äôd say, is not to be aware of why it is important to really understand the aims and foundations of the methods we implement. It is not until we do that, that we can make accurate and informed method selections based on the features of our data, detect unexpected and error-announcing results and interpret them correctly, map potential limitations of our analyses and draw rigorous meaningful conclusions from them."
  }
]